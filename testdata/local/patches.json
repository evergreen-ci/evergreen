{"_id": {"$oid": "5e4ff3abe3c3317e352062e4"},"desc": "'evergreen-ci/evergreen' pull request #3186 by bsamek: EVG-7425 Don't send ShouldExit to unprovisioned hosts (https://github.com/evergreen-ci/evergreen/pull/3186)", "branch": "evergreen", "alias": "__commit_queue", "githash": "5e823e1f28baeaa22ae00823d83e03082cd148ab", "patch_number": 2567, "author": "admin", "version": "5e4ff3abe3c3317e352062e4", "status": "failed", "create_time": { "$date": "2020-02-21T15:13:28Z" }, "start_time": { "$date": "2020-02-21T15:14:26.122Z" }, "finish_time": { "$date": "2020-02-21T15:29:54.869Z" }, "build_variants": ["ubuntu1604", "lint"], "tasks": [ "test-model-host", "test-model-artifact", "test-model-distro", "test-cloud", "test-validator", "test-plugin", "test-command", "test-db", "test-operations", "test-units", "test-model", "test-model-user", "test-model-stats", "js-test", "test-model-commitqueue", "test-monitor", "test-migrations", "test-scheduler", "test-util", "test-model-notification", "test-model-patch", "test-rest-route", "test-repotracker", "test-model-task", "test-rest-data", "test-model-manifest", "test-model-testresult", "test-model-grid", "test-model-build", "test-model-event", "test-trigger", "test-model-alertrecord", "test-service", "test-evergreen", "test-rest-model", "test-auth", "generate-lint", "test-rest-client", "test-thirdparty-docker", "test-agent", "test-graphql", "test-thirdparty" ], "variants_tasks": [{ "variant": "ubuntu1604", "tasks": [ "test-validator", "test-model-artifact", "test-model-distro", "test-migrations", "test-units", "test-operations", "test-thirdparty", "test-trigger", "test-model", "test-model-user", "test-thirdparty-docker", "test-cloud", "test-rest-client", "test-model-alertrecord", "test-model-stats", "test-plugin", "test-service", "test-evergreen", "test-rest-model", "test-agent", "test-rest-data", "test-util", "test-model-notification", "test-model-patch", "test-auth", "test-rest-route", "test-model-manifest", "test-repotracker", "js-test", "test-model-task", "test-model-commitqueue", "test-command", "test-graphql", "test-model-testresult", "test-model-grid", "test-monitor", "test-model-host", "test-model-build", "test-model-event", "test-db", "test-scheduler" ], "displaytasks": [] }, { "variant": "lint", "tasks": ["generate-lint"], "displaytasks": [] } ], "git_info": {"username": "bsamek", "email": "brian@mongodb.com"}, "patches": [{ "name": "", "githash": "5e823e1f28baeaa22ae00823d83e03082cd148ab", "patch_set": { "patch_file_id": "5e4ff3ab850e6136624eaf95", "summary": [{ "filename": "service/api_task.go", "additions": 5, "deletions": 4, "description": "ramen is amazing" }] }, "message": "", "is_mbox": true }, { "name": "Spruce", "githash": "5e823e1f28baeaa22ae0082383e03082cd148ab", "patch_set": { "patch_file_id": "5e4ff3ab850e6136624eaf95", "summary": [{ "filename": "src/pages/Task.tsx", "additions": 3, "deletions": 0, "description": "some other commit" },{ "filename": "src/App.tsx", "description": "crazy cool commit!!!", "additions": 0, "deletions": 32 },{ "filename": "src/pages/Patch.tsx", "additions": 55, "deletions": 22, "description": "mega commit" }] }, "message": "", "is_mbox": true }], "activated": true, "patched_config": "command_type: test\nstepback: true\nignore:\n  - \"*.md\" # don't schedule tests if a commit only changes markdown files\n  - \"scripts/*\" # our scripts are untested, so don't schedule tests for them\n  - \".github/*\" # github CODEOWNERS configuration\n\npost:\n  - func: attach-test-results\n  - command: s3.put\n    type: system\n    params:\n      aws_key: ${aws_key}\n      aws_secret: ${aws_secret}\n      local_files_include_filter:\n        [\n          \"gopath/src/github.com/evergreen-ci/evergreen/bin/output.*.coverage.html\",\n        ]\n      remote_file: evergreen/${task_id}/\n      bucket: mciuploads\n      content_type: text/html\n      permissions: public-read\n      display_name: \"(html) coverage:\"\n  - command: s3.put\n    type: system\n    params:\n      aws_key: ${aws_key}\n      aws_secret: ${aws_secret}\n      local_files_include_filter:\n        [\"gopath/src/github.com/evergreen-ci/evergreen/bin/output.*.coverage\"]\n      remote_file: evergreen/${task_id}/\n      bucket: mciuploads\n      content_type: text/plain\n      permissions: public-read\n      display_name: \"(txt) coverage:\"\n\n#######################################\n#         YAML Templates              #\n#######################################\nvariables:\n  - &run-build\n    # runs a build operations. The task name in evergreen should\n    # correspond to a make target for the build operation.\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n      - command: s3.put\n        type: system\n        params:\n          optional: true\n          aws_key: ${aws_key}\n          aws_secret: ${aws_secret}\n          local_file: gopath/src/github.com/evergreen-ci/evergreen/bin/dist.tar.gz\n          remote_file: evergreen/${build_id}-${build_variant}/evergreen-${task_name}-${revision}.tar.gz\n          bucket: mciuploads\n          content_type: application/x-gzip\n          permissions: public-read\n          display_name: dist.tar.gz\n  - &run-go-test-suite\n    # runs a make target and then uploads gotest output to\n    # evergreen. The test name should correspond to a make target for\n    # that suite\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - &run-go-test-suite-with-docker\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: setup-docker-host\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - &run-go-test-suite-with-mongodb\n    # runs a make target above, but only on systems that have a\n    # running mongod started for testing.\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - &run-go-test-suite-with-mongodb-useast\n    # runs a make target above, but only on systems that have a\n    # running mongod started for testing.\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\", tz: \"America/New_York\" }\n  - &run-smoke-test\n    name: smoke\n    commands:\n      - command: timeout.update\n        params:\n          exec_timeout_secs: 900\n          timeout_secs: 900\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-mongodb\n      - func: run-make\n        vars: { target: \"set-var\" }\n      - func: run-make\n        vars: { target: \"set-project-var\" }\n      - func: run-make\n        vars: { target: \"load-smoke-data\" }\n      - command: subprocess.exec\n        params:\n          silent: true\n          working_dir: gopath/src/github.com/evergreen-ci/evergreen\n          command: bash scripts/setup-smoke-config.sh ${github_token}\n      - func: run-make\n        vars:\n          target: set-smoke-vars\n      - func: run-make\n        vars:\n          target: \"${task_name}\"\n  - &run-smoke-test-with-client-url\n    name: smoke\n    commands:\n      - command: timeout.update\n        params:\n          exec_timeout_secs: 900\n          timeout_secs: 900\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: run-make\n        vars: { target: \"cli\" }\n      - command: s3.put\n        type: system\n        params:\n          aws_key: ${aws_key}\n          aws_secret: ${aws_secret}\n          local_file: gopath/src/github.com/evergreen-ci/evergreen/clients/${goos}_${goarch}/evergreen\n          remote_file: evergreen/${task_id}/evergreen-ci/evergreen/clients/${goos}_${goarch}/evergreen\n          bucket: mciuploads\n          content_type: application/octet-stream\n          permissions: public-read\n          display_name: evergreen\n      - func: setup-mongodb\n      - func: run-make\n        vars: { target: \"set-var\" }\n      - func: run-make\n        vars: { target: \"set-project-var\" }\n      - func: run-make\n        vars: { target: \"load-smoke-data\" }\n      - command: subprocess.exec\n        params:\n          silent: true\n          working_dir: gopath/src/github.com/evergreen-ci/evergreen\n          command: bash scripts/setup-smoke-config.sh ${github_token}\n      - func: run-make\n        vars:\n          target: set-smoke-vars\n      - func: run-make\n        vars:\n          target: \"${task_name}\"\n  - &version-constants\n    nodejs_version: \"6.11.1\"\n  - &run-generate-lint\n    name: generate-lint\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n      - command: s3.put\n        type: system\n        params:\n          aws_key: ${aws_key}\n          aws_secret: ${aws_secret}\n          local_file: gopath/src/github.com/evergreen-ci/evergreen/bin/generate-lint.json\n          remote_file: evergreen/${build_id}-${build_variant}/bin/generate-lint.json\n          bucket: mciuploads\n          content_type: application/json\n          permissions: public-read\n          display_name: generate-lint.json\n      - command: generate.tasks\n        params:\n          files:\n            - gopath/src/github.com/evergreen-ci/evergreen/bin/generate-lint.json\n\n#######################################\n#              Functions              #\n#######################################\nfunctions:\n  get-project:\n    command: git.get_project\n    type: setup\n    params:\n      directory: gopath/src/github.com/evergreen-ci/evergreen\n      token: ${github_token}\n      shallow_clone: true\n  run-make:\n    command: subprocess.exec\n    params:\n      working_dir: gopath/src/github.com/evergreen-ci/evergreen\n      binary: make\n      args: [\"${make_args|}\", \"${target}\"]\n      env:\n        AWS_KEY: ${aws_key}\n        AWS_SECRET: ${aws_secret}\n        CLIENT_URL: https://s3.amazonaws.com/mciuploads/evergreen/${task_id}/evergreen-ci/evergreen/clients/${goos}_${goarch}/evergreen\n        DEBUG_ENABLED: ${debug}\n        DISABLE_COVERAGE: ${disable_coverage}\n        DOCKER_HOST: ${docker_host}\n        EVERGREEN_ALL: \"true\"\n        GOARCH: ${goarch}\n        GO_BIN_PATH: ${gobin}\n        LEGACY_GO_BIN_PATH: ${legacyGobin}\n        GOOS: ${goos}\n        GOPATH: ${workdir}/gopath\n        GOROOT: ${goroot}\n        IS_DOCKER: ${is_docker}\n        KARMA_REPORTER: junit\n        NODE_BIN_PATH: ${nodebin}\n        RACE_DETECTOR: ${race_detector}\n        SETTINGS_OVERRIDE: creds.yml\n        SMOKE_TEST_FILE: ${smoke_test_file}\n        TEST_TIMEOUT: ${test_timeout}\n        TZ: ${tz}\n        VENDOR_PKG: \"github.com/${trigger_repo_owner}/${trigger_repo_name}\"\n        VENDOR_REVISION: ${trigger_revision}\n        XC_BUILD: ${xc_build}\n  setup-credentials:\n    command: subprocess.exec\n    type: setup\n    params:\n      silent: true\n      working_dir: gopath/src/github.com/evergreen-ci/evergreen\n      env:\n        GITHUB_TOKEN: ${github_token}\n        JIRA_SERVER: ${jiraserver}\n        CROWD_SERVER: ${crowdserver}\n        CROWD_USER: ${crowduser}\n        CROWD_PW: ${crowdpw}\n        AWS_KEY: ${aws_key}\n        AWS_SECRET: ${aws_secret}\n      command: bash scripts/setup-credentials.sh\n  setup-mongodb:\n    - command: subprocess.exec\n      type: setup\n      params:\n        env:\n          gobin: /opt/golang/go1.9/bin/go\n          MONGODB_URL: ${mongodb_url}\n          DECOMPRESS: ${decompress}\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen/\n        command: make get-mongodb\n    - command: subprocess.exec\n      type: setup\n      params:\n        background: true\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen/\n        command: make start-mongod\n    - command: subprocess.exec\n      type: setup\n      params:\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen\n        command: make check-mongod\n    - command: subprocess.exec\n      type: setup\n      params:\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen/\n        command: make init-rs\n  setup_docker:\n    - command: shell.exec\n      params:\n        shell: bash\n        script: |\n          gopath/src/github.com/evergreen-ci/evergreen/scripts/setup-docker.sh\n  setup-docker-host:\n    - command: host.create\n      type: setup\n      params:\n        distro: archlinux-parent\n        provider: ec2\n        retries: 3\n        scope: build\n        security_group_ids:\n          - sg-097bff6dd0d1d31d0\n    - command: host.list\n      type: setup\n      params:\n        wait: true\n        timeout_seconds: 900\n        num_hosts: 1\n        path: gopath/src/github.com/evergreen-ci/evergreen/spawned_hosts.json\n    - command: subprocess.exec\n      type: setup\n      params:\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen\n        command: make parse-host-file\n        env:\n          HOST_FILE: spawned_hosts.json\n          GO_BIN_PATH: ${gobin}\n          GOROOT: ${goroot}\n    - command: expansions.update\n      params:\n        file: gopath/src/github.com/evergreen-ci/evergreen/bin/expansions.yml\n\n  attach-test-results:\n    - command: gotest.parse_files\n      type: system\n      params:\n        files:\n          - \"gopath/src/github.com/evergreen-ci/evergreen/bin/output.*\"\n    - command: attach.xunit_results\n      type: system\n      params:\n        files:\n          - \"gopath/src/github.com/evergreen-ci/evergreen/bin/jstests/*.xml\"\n  remove-test-results:\n    - command: shell.exec\n      type: system\n      params:\n        shell: bash\n        script: |\n          set -o xtrace\n          rm gopath/src/github.com/evergreen-ci/evergreen/bin/output.*\n          rm gopath/src/github.com/evergreen-ci/evergreen/bin/jstests/*.xml\n\n#######################################\n#                Tasks                #\n#######################################\n\ntasks:\n  - name: coverage\n    tags: [\"report\"]\n    commands:\n      - command: git.get_project\n        type: setup\n        params:\n          directory: gopath/src/github.com/evergreen-ci/evergreen\n          token: ${github_token}\n          shallow_clone: false\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: build\n      - func: run-make\n        vars:\n          target: \"coverage-html\"\n          make_args: \"-k\"\n          tz: \"America/New_York\"\n\n  - <<: *run-build\n    name: dist-staging\n    patch_only: true\n\n  - <<: *run-smoke-test\n    name: smoke-test-task\n    tags: [\"smoke\"]\n  - <<: *run-smoke-test\n    name: smoke-test-endpoints\n    tags: [\"smoke\"]\n  - <<: *run-smoke-test-with-client-url\n    name: smoke-test-agent-monitor\n    tags: [\"smoke\"]\n  - <<: *run-generate-lint\n\n  - <<: *run-go-test-suite\n    name: js-test\n  - <<: *run-build\n    name: dist\n  - <<: *run-go-test-suite\n    tags: [\"nodb\", \"test\", \"agent\"]\n    name: test-thirdparty-docker\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-auth\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-rest-route\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"agent\"]\n    name: test-rest-client\n  - name: test-rest-model\n    tags: [\"db\", \"test\"]\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars:\n          target: build\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"test\", \"db\", \"agent\"]\n    name: test-command\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"test\", \"db\"]\n    name: test-units\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"agent\"]\n    name: test-agent\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-rest-data\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"cli\"]\n    name: test-operations\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-db\n  - <<: *run-go-test-suite-with-docker\n    tags: [\"db\", \"test\"]\n    name: test-cloud\n  - <<: *run-go-test-suite\n    tags: [\"nodb\", \"test\"]\n    name: test-cloud-userdata\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-scheduler\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-service\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-evergreen\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"agent\"]\n    name: test-thirdparty\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-trigger\n  - <<: *run-go-test-suite\n    tags: [\"nodb\", \"test\", \"agent\"]\n    name: test-util\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-validator\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-alertrecord\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-artifact\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-build\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-event\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-host\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-notification\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-patch\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-stats\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-task\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-testresult\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-user\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-distro\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-commitqueue\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-manifest\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-plugin\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-migrations\n  - <<: *run-go-test-suite-with-mongodb-useast\n    tags: [\"db\", \"test\"]\n    name: test-graphql\n  - name: docker-cleanup\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup_docker\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"test-thirdparty-docker\" }\n  - name: test-repotracker\n    tags: [\"db\", \"test\"]\n    commands:\n      - command: git.get_project\n        type: setup\n        params:\n          directory: gopath/src/github.com/evergreen-ci/evergreen\n          token: ${github_token}\n          shallow_clone: false\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"test-repotracker\" }\n\nbuildvariants:\n  - name: ubuntu1604\n    display_name: Ubuntu 16.04\n    run_on:\n      - ubuntu1604-test\n      - ubuntu1604-build\n    expansions:\n      disable_coverage: yes\n      goos: linux\n      goarch: amd64\n      nodebin: /opt/node/bin\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz\n    tasks:\n      - name: \"dist\"\n      - name: \"dist-staging\"\n      - name: \".smoke\"\n      - name: \".test\"\n      - name: \"js-test\"\n\n  - name: ubuntu1604-docker\n    display_name: Ubuntu 16.04 (Docker)\n    run_on:\n      - ubuntu1604-container\n    expansions:\n      goos: linux\n      goarch: amd64\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.3.tgz\n      test_timeout: 15m\n      nodebin: /opt/node/bin\n      is_docker: \"true\"\n    tasks:\n      - name: \"dist\"\n      - name: \".smoke\"\n      - name: \".test\"\n\n  - name: race-detector\n    display_name: Race Detector\n    run_on:\n      - archlinux-test\n      - archlinux-build\n    expansions:\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.3.tgz\n      race_detector: true\n      test_timeout: 15m\n    tasks:\n      - name: \".test\"\n\n  - name: lint\n    display_name: Lint\n    run_on:\n      - archlinux-test\n      - archlinux-build\n    expansions:\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n    tasks:\n      - name: generate-lint\n\n  - name: coverage\n    display_name: Coverage\n    run_on:\n      - archlinux-test\n      - archlinux-build\n    expansions:\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.3.tgz\n      test_timeout: 15m\n    tasks:\n      - name: \".report\"\n        stepback: false\n\n  - name: osx\n    display_name: OSX\n    batchtime: 2880\n    run_on:\n      - macos-1014\n    expansions:\n      disable_coverage: yes\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/osx/mongodb-osx-ssl-x86_64-4.0.3.tgz\n    tasks:\n      - name: \"dist\"\n      - name: \".test\"\n\n  - name: windows\n    display_name: Windows\n    run_on:\n      - windows-64-vs2015-small\n      - windows-64-vs2015-test\n      - windows-64-vs2015-small\n      - windows-64-vs2015-large\n      - windows-64-vs2015-compile\n      - windows-64-vs2013-test\n      - windows-64-vs2013-compile\n      - windows-64-vs2017-test\n      - windows-64-vs2017-compile\n    expansions:\n      disable_coverage: yes\n      gobin: /cygdrive/c/golang/go1.11/bin/go\n      goroot: c:/golang/go1.11\n      legacyGobin: /cygdrive/c/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/win32/mongodb-win32-x86_64-2008plus-ssl-4.0.3.zip\n      extension: \".exe\"\n      archiveExt: \".zip\"\n    tasks:\n      - name: \".agent .test\"\n      - name: \".cli .test\"\n\n  - name: ubuntu1604-arm64\n    display_name: Ubuntu 16.04 ARM\n    batchtime: 2880\n    run_on:\n      - ubuntu1604-arm64-small\n    expansions:\n      disable_coverage: yes\n      xc_build: yes\n      goarch: arm64\n      goos: linux\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://downloads.mongodb.com/linux/mongodb-linux-arm64-enterprise-ubuntu1604-4.0.3.tgz\n    tasks:\n      - name: \".agent .test\"\n  - name: linux-docker\n    display_name: ArchLinux (Docker)\n    run_on:\n      - archlinux-test\n    expansions:\n      goos: linux\n      goarch: amd64\n    tasks:\n      - name: \"docker-cleanup\"\n", "github_patch_data": { "pr_number": 3186, "base_owner": "evergreen-ci", "base_repo": "evergreen", "base_branch": "main", "head_owner": "bsamek", "head_repo": "evergreen", "head_hash": "a7ecb8d2cbaf02ada80e94b70d5d53efe45d9ed6", "author": "bsamek", "author_uid": 624531, "merge_commit_sha": "" },"parameters": [{"key": "my_param", "value": "my_value"}]}
{ "_id" : {"$oid": "5e6bb9e23066155a993e0f1a"}, "desc" : "test meee", "branch" : "evergreen", "githash" : "25ab18d7ed2775f27be77d8135ddd841c78cfe28", "patch_number" : 452, "author" : "admin", "version" : "", "status" : "created", "create_time" : {"$date": "2020-03-13T16:50:42.981Z"}, "start_time" : {"$date": "0001-01-01T00:00:00Z"}, "finish_time" : {"$date": "0001-01-01T00:00:00Z"}, "build_variants" : [ "ubuntu1604" ], "tasks" : [ "test-graphql" ], "variants_tasks" : [ { "variant" : "ubuntu1604", "tasks" : [ "test-graphql" ], "displaytasks" : [ ] } ], "patches" : [], "activated" : false, "alias" : "", "patched_config" : "command_type: test\nstepback: true\nignore:\n  - \"*.md\" # don't schedule tests if a commit only changes markdown files\n  - \"scripts/*\" # our scripts are untested, so don't schedule tests for them\n  - \".github/*\" # github CODEOWNERS configuration\n\npost:\n  - func: attach-test-results\n  - command: s3.put\n    type: system\n    params:\n      aws_key: ${aws_key}\n      aws_secret: ${aws_secret}\n      local_files_include_filter:\n        [\n          \"gopath/src/github.com/evergreen-ci/evergreen/bin/output.*.coverage.html\",\n        ]\n      remote_file: evergreen/${task_id}/\n      bucket: mciuploads\n      content_type: text/html\n      permissions: public-read\n      display_name: \"(html) coverage:\"\n  - command: s3.put\n    type: system\n    params:\n      aws_key: ${aws_key}\n      aws_secret: ${aws_secret}\n      local_files_include_filter:\n        [\"gopath/src/github.com/evergreen-ci/evergreen/bin/output.*.coverage\"]\n      remote_file: evergreen/${task_id}/\n      bucket: mciuploads\n      content_type: text/plain\n      permissions: public-read\n      display_name: \"(txt) coverage:\"\n\n#######################################\n#         YAML Templates              #\n#######################################\nvariables:\n  - &run-build\n    # runs a build operations. The task name in evergreen should\n    # correspond to a make target for the build operation.\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n      - command: s3.put\n        type: system\n        params:\n          optional: true\n          aws_key: ${aws_key}\n          aws_secret: ${aws_secret}\n          local_file: gopath/src/github.com/evergreen-ci/evergreen/bin/${task_name}.tar.gz\n          remote_file: evergreen/${build_id}-${build_variant}/evergreen-${task_name}-${revision}.tar.gz\n          bucket: mciuploads\n          content_type: application/x-gzip\n          permissions: public-read\n          display_name: dist.tar.gz\n  - &run-go-test-suite\n    # runs a make target and then uploads gotest output to\n    # evergreen. The test name should correspond to a make target for\n    # that suite\n    name: test\n    commands:\n      - func: get-project\n      - func: setup-credentials\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - &run-go-test-suite-with-docker\n    name: test\n    commands:\n      - func: get-project\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: setup-docker-host\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - &run-go-test-suite-with-mongodb\n    # runs a make target above, but only on systems that have a\n    # running mongod started for testing.\n    name: test\n    commands:\n      - func: get-project\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - &run-go-test-suite-with-mongodb-useast\n    # runs a make target above, but only on systems that have a\n    # running mongod started for testing.\n    name: test\n    commands:\n      - func: get-project\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\", tz: \"America/New_York\" }\n  - &run-smoke-test\n    name: smoke\n    commands:\n      - command: timeout.update\n        params:\n          exec_timeout_secs: 900\n          timeout_secs: 900\n      - func: get-project\n      - func: setup-mongodb\n      - func: run-make\n        vars: { target: \"set-var\" }\n      - func: run-make\n        vars: { target: \"set-project-var\" }\n      - func: run-make\n        vars: { target: \"load-smoke-data\" }\n      - command: subprocess.exec\n        params:\n          silent: true\n          working_dir: gopath/src/github.com/evergreen-ci/evergreen\n          command: bash scripts/setup-smoke-config.sh ${github_token}\n      - func: run-make\n        vars:\n          target: set-smoke-vars\n      - func: run-make\n        vars:\n          target: \"${task_name}\"\n  - &run-smoke-test-with-client-url\n    name: smoke\n    commands:\n      - command: timeout.update\n        params:\n          exec_timeout_secs: 900\n          timeout_secs: 900\n      - func: get-project\n      - func: run-make\n        vars: { target: \"cli\" }\n      - command: s3.put\n        type: system\n        params:\n          aws_key: ${aws_key}\n          aws_secret: ${aws_secret}\n          local_file: gopath/src/github.com/evergreen-ci/evergreen/clients/${goos}_${goarch}/evergreen\n          remote_file: evergreen/${task_id}/evergreen-ci/evergreen/clients/${goos}_${goarch}/evergreen\n          bucket: mciuploads\n          content_type: application/octet-stream\n          permissions: public-read\n          display_name: evergreen\n      - func: setup-mongodb\n      - func: run-make\n        vars: { target: \"set-var\" }\n      - func: run-make\n        vars: { target: \"set-project-var\" }\n      - func: run-make\n        vars: { target: \"load-smoke-data\" }\n      - command: subprocess.exec\n        params:\n          silent: true\n          working_dir: gopath/src/github.com/evergreen-ci/evergreen\n          command: bash scripts/setup-smoke-config.sh ${github_token}\n      - func: run-make\n        vars:\n          target: set-smoke-vars\n      - func: run-make\n        vars:\n          target: \"${task_name}\"\n  - &version-constants\n    nodejs_version: \"6.11.1\"\n  - &run-generate-lint\n    name: generate-lint\n    commands:\n      - func: get-project\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n      - command: s3.put\n        type: system\n        params:\n          aws_key: ${aws_key}\n          aws_secret: ${aws_secret}\n          local_file: gopath/src/github.com/evergreen-ci/evergreen/bin/generate-lint.json\n          remote_file: evergreen/${build_id}-${build_variant}/bin/generate-lint.json\n          bucket: mciuploads\n          content_type: application/json\n          permissions: public-read\n          display_name: generate-lint.json\n      - command: generate.tasks\n        params:\n          files:\n            - gopath/src/github.com/evergreen-ci/evergreen/bin/generate-lint.json\n\n#######################################\n#              Functions              #\n#######################################\nfunctions:\n  get-project:\n    command: git.get_project\n    type: setup\n    params:\n      directory: gopath/src/github.com/evergreen-ci/evergreen\n      token: ${github_token}\n      shallow_clone: true\n  run-make:\n    command: subprocess.exec\n    params:\n      working_dir: gopath/src/github.com/evergreen-ci/evergreen\n      binary: make\n      args: [\"${make_args|}\", \"${target}\"]\n      env:\n        AWS_KEY: ${aws_key}\n        AWS_SECRET: ${aws_secret}\n        CLIENT_URL: https://s3.amazonaws.com/mciuploads/evergreen/${task_id}/evergreen-ci/evergreen/clients/${goos}_${goarch}/evergreen\n        DEBUG_ENABLED: ${debug}\n        DISABLE_COVERAGE: ${disable_coverage}\n        DOCKER_HOST: ${docker_host}\n        EVERGREEN_ALL: \"true\"\n        GOARCH: ${goarch}\n        GO_BIN_PATH: ${gobin}\n        LEGACY_GO_BIN_PATH: ${legacyGobin}\n        GOOS: ${goos}\n        GOPATH: ${workdir}/gopath\n        GOROOT: ${goroot}\n        IS_DOCKER: ${is_docker}\n        KARMA_REPORTER: junit\n        NODE_BIN_PATH: ${nodebin}\n        RACE_DETECTOR: ${race_detector}\n        SETTINGS_OVERRIDE: creds.yml\n        SMOKE_TEST_FILE: ${smoke_test_file}\n        TEST_TIMEOUT: ${test_timeout}\n        TZ: ${tz}\n        VENDOR_PKG: \"github.com/${trigger_repo_owner}/${trigger_repo_name}\"\n        VENDOR_REVISION: ${trigger_revision}\n        XC_BUILD: ${xc_build}\n  setup-credentials:\n    command: subprocess.exec\n    type: setup\n    params:\n      silent: true\n      working_dir: gopath/src/github.com/evergreen-ci/evergreen\n      env:\n        GITHUB_TOKEN: ${github_token}\n        JIRA_SERVER: ${jiraserver}\n        CROWD_SERVER: ${crowdserver}\n        CROWD_USER: ${crowduser}\n        CROWD_PW: ${crowdpw}\n        AWS_KEY: ${aws_key}\n        AWS_SECRET: ${aws_secret}\n      command: bash scripts/setup-credentials.sh\n  setup-mongodb:\n    - command: subprocess.exec\n      type: setup\n      params:\n        env:\n          gobin: /opt/golang/go1.9/bin/go\n          MONGODB_URL: ${mongodb_url}\n          DECOMPRESS: ${decompress}\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen/\n        command: make get-mongodb\n    - command: subprocess.exec\n      type: setup\n      params:\n        background: true\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen/\n        command: make start-mongod\n    - command: subprocess.exec\n      type: setup\n      params:\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen\n        command: make check-mongod\n    - command: subprocess.exec\n      type: setup\n      params:\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen/\n        command: make init-rs\n  setup_docker:\n    - command: shell.exec\n      params:\n        shell: bash\n        script: |\n          gopath/src/github.com/evergreen-ci/evergreen/scripts/setup-docker.sh\n  setup-docker-host:\n    - command: host.create\n      type: setup\n      params:\n        distro: archlinux-parent\n        provider: ec2\n        retries: 3\n        scope: build\n        security_group_ids:\n          - sg-097bff6dd0d1d31d0\n    - command: host.list\n      type: setup\n      params:\n        wait: true\n        timeout_seconds: 900\n        num_hosts: 1\n        path: gopath/src/github.com/evergreen-ci/evergreen/spawned_hosts.json\n    - command: subprocess.exec\n      type: setup\n      params:\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen\n        command: make parse-host-file\n        env:\n          HOST_FILE: spawned_hosts.json\n          GO_BIN_PATH: ${gobin}\n          GOROOT: ${goroot}\n    - command: expansions.update\n      params:\n        file: gopath/src/github.com/evergreen-ci/evergreen/bin/expansions.yml\n\n  attach-test-results:\n    - command: gotest.parse_files\n      type: system\n      params:\n        files:\n          - \"gopath/src/github.com/evergreen-ci/evergreen/bin/output.*\"\n    - command: attach.xunit_results\n      type: system\n      params:\n        files:\n          - \"gopath/src/github.com/evergreen-ci/evergreen/bin/jstests/*.xml\"\n  remove-test-results:\n    - command: shell.exec\n      type: system\n      params:\n        shell: bash\n        script: |\n          set -o xtrace\n          rm gopath/src/github.com/evergreen-ci/evergreen/bin/output.*\n          rm gopath/src/github.com/evergreen-ci/evergreen/bin/jstests/*.xml\n\n#######################################\n#                Tasks                #\n#######################################\n\ntasks:\n  - name: coverage\n    tags: [\"report\"]\n    commands:\n      - func: get-project\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: \"coverage-html\"\n          make_args: \"-k\"\n          tz: \"America/New_York\"\n  - <<: *run-smoke-test\n    name: smoke-test-task\n    tags: [\"smoke\"]\n  - <<: *run-smoke-test\n    name: smoke-test-endpoints\n    tags: [\"smoke\"]\n  - <<: *run-smoke-test-with-client-url\n    name: smoke-test-agent-monitor\n    tags: [\"smoke\"]\n  - <<: *run-generate-lint\n\n  - <<: *run-go-test-suite\n    name: js-test\n  - <<: *run-build\n    name: dist\n  - <<: *run-go-test-suite\n    tags: [\"nodb\", \"test\", \"agent\"]\n    name: test-thirdparty-docker\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-auth\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-rest-route\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"agent\"]\n    name: test-rest-client\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-rest-model\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"test\", \"db\", \"agent\"]\n    name: test-command\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"test\", \"db\"]\n    name: test-units\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"agent\"]\n    name: test-agent\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-rest-data\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"cli\"]\n    name: test-operations\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-db\n  - <<: *run-go-test-suite-with-docker\n    tags: [\"db\", \"test\"]\n    name: test-cloud\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-scheduler\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-service\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-monitor\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-evergreen\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"agent\"]\n    name: test-thirdparty\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-trigger\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"nodb\", \"test\", \"agent\"]\n    name: test-util\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-validator\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-alertrecord\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-artifact\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-build\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-event\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-host\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-notification\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-patch\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-stats\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-task\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-testresult\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-user\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-distro\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-commitqueue\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-manifest\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-plugin\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-migrations\n  - <<: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-grid\n  - <<: *run-go-test-suite-with-mongodb-useast\n    tags: [\"db\", \"test\"]\n    name: test-graphql\n  - name: docker-cleanup\n    commands:\n      - func: get-project\n      - func: setup-credentials\n      - func: setup_docker\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"test-thirdparty-docker\" }\n  - name: test-repotracker\n    tags: [\"db\", \"test\"]\n    commands:\n      - command: git.get_project\n        type: setup\n        params:\n          directory: gopath/src/github.com/evergreen-ci/evergreen\n          token: ${github_token}\n          shallow_clone: false\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"test-repotracker\" }\n\nbuildvariants:\n  - name: ubuntu1604\n    display_name: Ubuntu 16.04\n    run_on:\n      - ubuntu1604-test\n      - ubuntu1604-build\n    expansions:\n      disable_coverage: yes\n      goos: linux\n      goarch: amd64\n      nodebin: /opt/node/bin\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz\n    tasks:\n      - name: \"dist\"\n      - name: \".smoke\"\n      - name: \".test\"\n      - name: \"js-test\"\n\n  - name: ubuntu1604-docker\n    display_name: Ubuntu 16.04 (Docker)\n    run_on:\n      - ubuntu1604-container\n    expansions:\n      goos: linux\n      goarch: amd64\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.3.tgz\n      test_timeout: 15m\n      nodebin: /opt/node/bin\n      is_docker: \"true\"\n    tasks:\n      - name: \"dist\"\n      - name: \".smoke\"\n      - name: \".test\"\n\n  - name: race-detector\n    display_name: Race Detector\n    run_on:\n      - archlinux-test\n      - archlinux-build\n    expansions:\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.3.tgz\n      race_detector: true\n      test_timeout: 15m\n    tasks:\n      - name: \".test\"\n\n  - name: lint\n    display_name: Lint\n    run_on:\n      - archlinux-test\n      - archlinux-build\n    expansions:\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n    tasks:\n      - name: generate-lint\n\n  - name: coverage\n    display_name: Coverage\n    run_on:\n      - archlinux-test\n      - archlinux-build\n    expansions:\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.3.tgz\n      test_timeout: 15m\n    tasks:\n      - name: \".report\"\n        stepback: false\n\n  - name: osx\n    display_name: OSX\n    batchtime: 2880\n    run_on:\n      - macos-1014\n    expansions:\n      disable_coverage: yes\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/osx/mongodb-osx-ssl-x86_64-4.0.3.tgz\n    tasks:\n      - name: \"dist\"\n      - name: \".test\"\n\n  - name: windows\n    display_name: Windows\n    run_on:\n      - windows-64-vs2015-small\n      - windows-64-vs2015-test\n      - windows-64-vs2015-small\n      - windows-64-vs2015-large\n      - windows-64-vs2015-compile\n      - windows-64-vs2013-test\n      - windows-64-vs2013-compile\n      - windows-64-vs2010-test\n      - windows-64-vs2010-compile\n      - windows-64-vs2017-test\n      - windows-64-vs2017-compile\n    expansions:\n      disable_coverage: yes\n      gobin: /cygdrive/c/golang/go1.11/bin/go\n      goroot: c:/golang/go1.11\n      legacyGobin: /cygdrive/c/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/win32/mongodb-win32-x86_64-2008plus-ssl-4.0.3.zip\n      extension: \".exe\"\n      archiveExt: \".zip\"\n    tasks:\n      - name: \".agent .test\"\n      - name: \".cli .test\"\n\n  - name: rhel71-power8\n    display_name: RHEL 7.1 POWER8\n    batchtime: 2880\n    run_on:\n      - rhel71-power8-test\n    expansions:\n      disable_coverage: yes\n      xc_build: yes\n      goarch: ppc64le\n      gobin: /opt/golang/go1.13/bin/go\n      legacyGobin: /opt/golang/go1.9/bin/go\n      goos: linux\n      goroot: /opt/golang/go1.13\n      mongodb_url: https://downloads.mongodb.com/linux/mongodb-linux-ppc64le-enterprise-rhel71-4.0.3.tgz\n    tasks:\n      - name: \".agent .test\"\n\n  - name: rhel72-s390x\n    display_name: RHEL 7.2 zLinux\n    batchtime: 2880\n    run_on:\n      - rhel72-zseries-test\n    expansions:\n      xc_build: yes\n      disable_coverage: yes\n      goarch: s390x\n      gobin: /opt/golang/go1.11/bin/go\n      goroot: /opt/golang/go1.11\n      legacyGobin: /opt/golang/go1.9/bin/go\n      goos: linux\n      # No official release of 4.0 for rhel72 zseries\n      mongodb_url: https://downloads.mongodb.com/linux/mongodb-linux-s390x-enterprise-rhel72-3.6.4.tgz\n    tasks:\n      - name: \".agent .test\"\n\n  - name: ubuntu1604-arm64\n    display_name: Ubuntu 16.04 ARM\n    batchtime: 2880\n    run_on:\n      - ubuntu1604-arm64-small\n    expansions:\n      disable_coverage: yes\n      xc_build: yes\n      goarch: arm64\n      goos: linux\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://downloads.mongodb.com/linux/mongodb-linux-arm64-enterprise-ubuntu1604-4.0.3.tgz\n    tasks:\n      - name: \".agent .test\"\n  - name: linux-docker\n    display_name: ArchLinux (Docker)\n    run_on:\n      - archlinux-test\n    expansions:\n      goos: linux\n      goarch: amd64\n    tasks:\n      - name: \"docker-cleanup\"\n" }
{ "_id" : {"$oid": "5dd2e89cd1fe07048e43bb9c"}, "desc" : "'evergreen-ci/spruce' pull request #27 by tgrander: Refactor App + Use Context for global state (https://github.com/evergreen-ci/spruce/pull/27)", "branch" : "spruce", "githash" : "3b53f9b61226491cd31113c773d66e351957ed29", "patch_number" : 20, "author" : "trey.granderson", "version" : "5dd2e89cd1fe07048e43bb9c", "status" : "failed", "create_time" : {"$date": "2019-11-18T18:53:15Z"}, "start_time" : {"$date": "2019-11-18T18:54:15.734Z"}, "finish_time" : {"$date": "2019-11-18T18:57:15.053Z"}, "build_variants" : [ "ubuntu1804" ], "tasks" : [ "compile", "test", "lint", "coverage" ], "variants_tasks" : [ { "variant" : "ubuntu1804", "tasks" : [ "lint", "coverage", "compile", "test" ], "displaytasks" : [ ] } ], "patches" : [ { "name" : "", "githash" : "3b53f9b61226491cd31113c773d66e351957ed29", "patch_set" : { "patch_file_id" : "5e4ff3ab850e6136624eaf95", "summary" : [ { "filename" : "package.json", "additions" : 2, "deletions" : 0 }, { "filename" : "src/components/Navbar.tsx", "additions" : 70, "deletions" : 0 }, { "filename" : "src/components/app/App.tsx", "additions" : 78, "deletions" : 289 }, { "filename" : "src/components/navbar/DevMenu.tsx", "additions" : 62, "deletions" : 0 }, { "filename" : "src/components/navbar/PluginsMenu.tsx", "additions" : 42, "deletions" : 0 }, { "filename" : "src/context/ContextProvider.tsx", "additions" : 11, "deletions" : 0 }, { "filename" : "src/context/apiClient.tsx", "additions" : 70, "deletions" : 0 }, { "filename" : "src/context/user.tsx", "additions" : 33, "deletions" : 0 }, { "filename" : "src/utils/isDevelopment.ts", "additions" : 1, "deletions" : 0 }, { "filename" : "tslint.json", "additions" : 1, "deletions" : 0 } ] }, "message" : "" } ], "activated" : true, "patched_config" : "stepback: true\ncommand_type: test\nignore:\n - \"*.md\"\n - \".github/*\"\n\nfunctions:\n get-project:\n command: git.get_project\n type: setup\n params:\n directory: spruce\n\n npm-install:\n command: subprocess.exec\n type: setup\n params:\n working_dir: spruce\n binary: npm\n args: [install]\n\n npm-test:\n command: subprocess.exec\n params:\n working_dir: spruce\n binary: npm\n args: [test, --, -u, --reporters=default, --reporters=jest-junit]\n env:\n CI: \"true\"\n\n npm-lint:\n command: subprocess.exec\n params:\n working_dir: spruce\n binary: npm\n args: [run, lint]\n\n npm-build:\n command: subprocess.exec\n params:\n working_dir: spruce\n binary: npm\n args: [run, build]\n\n npm-build:\n command: subprocess.exec\n params:\n working_dir: spruce\n binary: npm\n args: [run, build]\n\n npm-coverage:\n command: subprocess.exec\n params:\n working_dir: spruce\n binary: npm\n args: [run, coverage]\n\n attach-results:\n command: attach.xunit_results\n params:\n files:\n - \"./spruce/junit.xml\"\n\ntasks:\n - name: compile\n commands:\n - func: get-project\n - func: npm-install\n - func: npm-build\n - func: npm-build\n - name: test\n commands:\n - func: get-project\n - func: npm-install\n - func: npm-test\n - func: attach-results\n - name: lint\n commands:\n - func: get-project\n - func: npm-install\n - func: npm-lint\n - name: coverage\n commands:\n - func: get-project\n - func: npm-install\n - func: npm-coverage\n\nbuildvariants:\n - name: ubuntu1804\n display_name: Ubuntu 18.04\n run_on:\n - ubuntu1804-test\n tasks:\n - name: compile\n - name: test\n - name: lint\n - name: coverage\n", "alias" : "__github", "github_patch_data" : { "pr_number" : 27, "base_owner" : "evergreen-ci", "base_repo" : "spruce", "base_branch" : "main", "head_owner" : "evergreen-ci", "head_repo" : "spruce", "head_hash" : "2b37dacf86f9d4d1545faaba37c7c5693202e645", "author" : "tgrander", "author_uid" : 15262143, "merge_commit_sha" : "" } }
{"_id":{"$oid":"5e94c2dfe3c3312519b59480"},"desc":"SERVER-46893 Allow streamable isMaster to wait on removed/uninitialized nodes","branch":"mongodb-mongo-master", "githash":"0170e0a872373b388a48694d24f22da63983e5d0","patch_number":1387.0,"author":"mohamed.khelif","alias" : "__commit_queue", "version":"5e9748c4e3c331422d0d1d7c","status":"succeeded","create_time":{"$date":"2020-04-15T17:47:49.351Z"},"start_time":{"$date":"2020-04-15T17:49:04.806Z"},"finish_time":{"$date":"2020-04-15T18:04:05.785Z"},"build_variants":["commit-queue-merge","enterprise-rhel-62-64-bit","commit-queue"],"tasks":["lint_clang_format","lint_eslint","lint_errorcodes","lint_fuzzer_sanity_patch","compile_core_tools","commit_queue_placeholder","merge-patch","lint_yaml","validate_commit_message","lint_cpplint","lint_pylinters","dbtest"],"patches":[{"name":"","githash":"0170e0a872373b388a48694d24f22da63983e5d0","patch_set":{"patch_file_id":"5e4ff3ab850e6136624eaf95","summary":[{"filename":"jstests/replsets/awaitable_ismain_errors_on_horizon_change.js","additions":1.0,"deletions":1.0,"description":"SERVER-46893 Allow streamable isMaster to wait on"},{"filename":"jstests/replsets/awaitable_ismain_on_nodes_with_invalid_configs.js","additions":172.0,"deletions":0.0,"description":"SERVER-46893 Allow streamable isMaster to wait on"},{"filename":"src/mongo/db/repl/replication_coordinator.h","additions":2.0,"deletions":2.0,"description":"SERVER-46893 Allow streamable isMaster to wait on"}]},"message":"SERVER-46893 Allow streamable isMaster to wait on removed/uninitialized nodes"}]}
{"_id":{"$oid":"52420b363ff1222d23000002"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["windows-64-2k8-debug"],"create_time":{"$date":"2013-09-24T21:59:18.276Z"},"desc":"","githash":"14837002ef926c56f9ac3683127325833885594f","patches":[{"name":"","githash":"14837002ef926c56f9ac3683127325833885594f","patch_set":{"patch":"diff --git a/SConstruct b/SConstruct\nindex 65987dd..b3cbfe5 100644\n--- a/SConstruct\n+++ b/SConstruct\n@@ -475,6 +475,8 @@ if \"sunos5\" == os.sys.platform:\n     #  http://four.pairlist.net/pipermail/scons-users/2013-June/001486.html\n     env.Tool('gnulink')\n \n+if optBuild:\n+    env.Append( CPPDEFINES=[\"MONGO_OPTIMIZED_BUILD\"] )\n \n if has_option(\"propagate-shell-environment\"):\n     env['ENV'] = dict(os.environ);\ndiff --git a/src/mongo/db/client.cpp b/src/mongo/db/client.cpp\nindex 3c82d7a..737508f 100644\n--- a/src/mongo/db/client.cpp\n+++ b/src/mongo/db/client.cpp\n@@ -81,7 +81,7 @@ namespace mongo {\n \n     TSP_DEFINE(Client, currentClient)\n \n-#if defined(_DEBUG) && !XSAN_ENABLED\n+#if defined(_DEBUG) && !defined(MONGO_OPTIMIZED_BUILD) && !XSAN_ENABLED\n     struct StackChecker;\n     ThreadLocalValue<StackChecker *> checker;\n \n@@ -134,7 +134,7 @@ namespace mongo {\n        call this when your thread starts.\n     */\n     Client& Client::initThread(const char *desc, AbstractMessagingPort *mp) {\n-#if defined(_DEBUG) && !XSAN_ENABLED\n+#if defined(_DEBUG) && !defined(MONGO_OPTIMIZED_BUILD) && !XSAN_ENABLED\n         {\n             if( sizeof(void*) == 8 ) {\n                 StackChecker sc;\n@@ -230,7 +230,7 @@ namespace mongo {\n     }\n \n     bool Client::shutdown() {\n-#if defined(_DEBUG) && !XSAN_ENABLED\n+#if defined(_DEBUG) && !defined(MONGO_OPTIMIZED_BUILD) && !XSAN_ENABLED\n         {\n             if( sizeof(void*) == 8 ) {\n                 StackChecker::check( desc() );\ndiff --git a/src/mongo/dbtests/stacktests.cpp b/src/mongo/dbtests/stacktests.cpp\nindex 5e325d4..0c922af 100644\n--- a/src/mongo/dbtests/stacktests.cpp\n+++ b/src/mongo/dbtests/stacktests.cpp\n@@ -104,7 +104,9 @@ namespace StackTests {\n \n         void setupTests() {\n             if ( inConstructorChainSupported() ) {\n+#if defined(_DEBUG) && !defined(MONGO_OPTIMIZED_BUILD)\n                 DEV add< InCons >(); \n+#endif\n             }\n         }\n         \ndiff --git a/src/mongo/util/stack_introspect.cpp b/src/mongo/util/stack_introspect.cpp\nindex f79d42e..7d6c45e 100644\n--- a/src/mongo/util/stack_introspect.cpp\n+++ b/src/mongo/util/stack_introspect.cpp\n@@ -30,7 +30,7 @@\n \n #include \"mongo/util/stack_introspect.h\"\n \n-#if !defined(_WIN32)\n+#if !defined(_WIN32) && !defined(MONGO_OPTIMIZED_BUILD)\n \n #include <cstdlib>\n #include <cxxabi.h>\n@@ -205,4 +205,4 @@ namespace mongo {\n     bool inConstructorChainSupported() { return false; }\n }\n \n-#endif  // #if !defined(_WIN32)\n+#endif  // #if !defined(_WIN32) && !defined(MONGO_OPTIMIZED_BUILD)\n","summary":[{"filename":"SConstruct","additions":2,"deletions":0},{"filename":"src/mongo/db/client.cpp","additions":3,"deletions":3},{"filename":"src/mongo/dbtests/stacktests.cpp","additions":2,"deletions":0},{"filename":"src/mongo/util/stack_introspect.cpp","additions":2,"deletions":2}]}}],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"52460a9f3ff1226a3c000002"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["windows-64","windows-32","solaris-64-bit"],"create_time":{"$date":"2013-09-27T22:45:51.723Z"},"desc":"windows-64,windows-32,solaris-64-bit","githash":"7f3eab9a44d4e3f9fffa8b14fca3b61a444306c4","patches":[{"name":"","githash":"7f3eab9a44d4e3f9fffa8b14fca3b61a444306c4","patch_set":{"patch":"diff --git a/src/mongo/util/net/sock.cpp b/src/mongo/util/net/sock.cpp\nindex a50e8bb..b359bed 100644\n--- a/src/mongo/util/net/sock.cpp\n+++ b/src/mongo/util/net/sock.cpp\n@@ -487,14 +487,20 @@ namespace mongo {\n     public:\n         ConnectBG(int sock, SockAddr remote) : _sock(sock), _remote(remote) { }\n \n-        void run() { _res = ::connect(_sock, _remote.raw(), _remote.addressSize); }\n-        string name() const { return \"ConnectBG\"; }\n+        void run() {\n+            _res = ::connect(_sock, _remote.raw(), _remote.addressSize);\n+            _errnoWithDescription = errnoWithDescription();\n+        }\n+\n+        std::string name() const { return \"ConnectBG\"; }\n+        std::string getErrnoWithDescription() const { return _errnoWithDescription; }\n         int inError() const { return _res; }\n \n     private:\n         int _sock;\n         int _res;\n         SockAddr _remote;\n+        std::string _errnoWithDescription;\n     };\n \n     bool Socket::connect(SockAddr& remote) {\n@@ -514,6 +520,8 @@ namespace mongo {\n         bg.go();\n         if ( bg.wait(5000) ) {\n             if ( bg.inError() ) {\n+                warning() << \"Failed to connect to \" << _remote.getAddr()\n+                          << \", reason: \" << bg.getErrnoWithDescription() << endl;\n                 close();\n                 return false;\n             }\n","summary":[{"filename":"src/mongo/util/net/sock.cpp","additions":10,"deletions":2}]}}],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"524994ac3ff1226850000002"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["osx-108-cxx11-debug"],"create_time":{"$date":"2013-09-30T15:11:40.989Z"},"desc":"osx-108-cxx11-debug","githash":"8a2181ba012c8d28faeb5f5dd56cc7e19ae4ec56","patches":[{"name":"","githash":"8a2181ba012c8d28faeb5f5dd56cc7e19ae4ec56","patch_set":{"patch":"diff --git a/src/mongo/util/processinfo.cpp b/src/mongo/util/processinfo.cpp\nindex fd18180..a963ea3 100644\n--- a/src/mongo/util/processinfo.cpp\n+++ b/src/mongo/util/processinfo.cpp\n@@ -38,7 +38,7 @@ namespace mongo {\n             path = p;\n             ofstream out( path.c_str() , ios_base::out );\n             out << ProcessId::getCurrent() << endl;\n-            return out;\n+            return out.good();\n         }\n \n         string path;\n","summary":[{"filename":"src/mongo/util/processinfo.cpp","additions":1,"deletions":1}]}}],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"524f0a933ff1221bb8000001"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["linux-64"],"create_time":{"$date":"2013-10-04T18:36:03.666Z"},"desc":"linux-64","githash":"393194020e81707824b90622cf365333944133ef","patches":[{"name":"","githash":"393194020e81707824b90622cf365333944133ef","patch_set":{"patch":"diff --git a/src/mongo/db/repl/rs_config.cpp b/src/mongo/db/repl/rs_config.cpp\nindex fcef0cc..9b235df 100644\n--- a/src/mongo/db/repl/rs_config.cpp\n+++ b/src/mongo/db/repl/rs_config.cpp\n@@ -74,9 +74,7 @@ namespace mongo {\n         checkRsConfig();\n         log() << \"replSet info saving a newer config version to local.system.replset\" << rsLog;\n         {\n-            Lock::GlobalWrite lk; // TODO: does this really need to be a global lock?\n-            Client::Context cx( rsConfigNs );\n-            cx.db()->flushFiles(true);\n+            Client::WriteContext cx( rsConfigNs );\n \n             //theReplSet->lastOpTimeWritten = ??;\n             //rather than above, do a logOp()? probably\n@@ -85,7 +83,7 @@ namespace mongo {\n             if( !comment.isEmpty() && (!theReplSet || theReplSet->isPrimary()) )\n                 logOpInitiate(comment);\n \n-            cx.db()->flushFiles(true);\n+            cx.ctx().db()->flushFiles(true);\n         }\n         log() << \"replSet saveConfigLocally done\" << rsLog;\n     }\n","summary":[{"filename":"src/mongo/db/repl/rs_config.cpp","additions":2,"deletions":4}]}}],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"524f108d3ff1221bb8000002"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["all"],"create_time":{"$date":"2013-10-04T19:01:33.656Z"},"desc":"all","githash":"37a7f2f07fddce4e413a56753473a7333da35432","patches":[{"name":"","githash":"37a7f2f07fddce4e413a56753473a7333da35432","patch_set":{"patch":"diff --git a/jstests/count10.js b/jstests/count10.js\nindex cb2979d..478c30a 100644\n--- a/jstests/count10.js\n+++ b/jstests/count10.js\n@@ -9,26 +9,27 @@ for ( i=0; i<100; i++ ){\n // make sure data is written\n db.getLastError();\n \n-var thr = new Thread(function () {\n+s = startParallelShell(\n+    'sleep(1000); ' +\n+    'current = db.currentOp({\"ns\": db.count10.getFullName(), \"query.count\": db.count10.getName()}); ' +\n+    'assert(current); ' +\n+    'countOp = current.inprog[0]; ' +\n+    'assert(countOp); ' +\n+    'db.killOp(countOp.opid); '\n+);\n+\n+function getKilledCount() {\n     try {\n         db.count10.find(\"sleep(1000)\").count();\n-    }\n-    catch (e) {\n+    } catch (e) {\n         return e;\n     }\n-});\n-\n-thr.start();\n-sleep(1000);\n-\n-current = db.currentOp({\"ns\": t.getFullName(), \"query.count\": t.getName()});\n-assert(current);\n-countOp = current.inprog[0];\n-assert(countOp);\n-\n-db.killOp(countOp.opid);\n-res = thr.returnData();\n+}\n \n+var res = getKilledCount();\n assert(res);\n assert(res.match(/count failed/) !== null);\n assert(res.match(/\\\"code\\\"/) !== null);\n+\n+s();\n+\n","summary":[{"filename":"jstests/count10.js","additions":16,"deletions":15}]}}],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"52542ded3ff1221444000002"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["linux-64-duroff","linux-64-debug-duroff"],"create_time":{"$date":"2013-10-08T16:08:13.059Z"},"desc":"linux-64-duroff,linux-64-debug-duroff","githash":"0b40bfbd29511acf9f075df34c048b1b98cf0094","patches":[{"name":"","githash":"0b40bfbd29511acf9f075df34c048b1b98cf0094","patch_set":{"patch":"diff --git a/jstests/find_and_modify4.js b/jstests/find_and_modify4.js\nindex 5f34318..7af7b0e 100644\n--- a/jstests/find_and_modify4.js\n+++ b/jstests/find_and_modify4.js\n@@ -9,15 +9,15 @@ function getNextVal(counterName){\n                 upsert: true,\n                 'new': true,\n                 });\n-    return ret.val;\n+    return ret;\n }\n \n-assert.eq(getNextVal(\"a\"), 1);\n-assert.eq(getNextVal(\"a\"), 2);\n-assert.eq(getNextVal(\"a\"), 3);\n-assert.eq(getNextVal(\"z\"), 1);\n-assert.eq(getNextVal(\"z\"), 2);\n-assert.eq(getNextVal(\"a\"), 4);\n+assert.eq(getNextVal(\"a\"), {_id:\"a\", val:1});\n+assert.eq(getNextVal(\"a\"), {_id:\"a\", val:2});\n+assert.eq(getNextVal(\"a\"), {_id:\"a\", val:3});\n+assert.eq(getNextVal(\"z\"), {_id:\"z\", val:1});\n+assert.eq(getNextVal(\"z\"), {_id:\"z\", val:2});\n+assert.eq(getNextVal(\"a\"), {_id:\"a\", val:4});\n \n t.drop();\n \ndiff --git a/jstests/upsert1.js b/jstests/upsert1.js\nindex 77cbf57..07b6159 100644\n--- a/jstests/upsert1.js\n+++ b/jstests/upsert1.js\n@@ -1,14 +1,52 @@\n-\n+// tests to make sure that the new _id is returned after the insert\n t = db.upsert1;\n t.drop();\n \n+// make sure the new _id is returned when $mods are used\n t.update( { x : 1 } , { $inc : { y : 1 } } , true );\n l = db.getLastErrorCmd();\n-assert( l.upserted , \"A1\" );\n+assert( l.upserted , \"A1 - \" + tojson(l) );\n assert.eq( l.upserted.str , t.findOne()._id.str , \"A2\" );\n \n+// make sure the new _id is returned on a replacement (no $mod in update)\n t.update( { x : 2 } , { x : 2 , y : 3 } , true );\n l = db.getLastErrorCmd();\n-assert( l.upserted , \"B1\" );\n+assert( l.upserted , \"B1 - \" + tojson(l) );\n assert.eq( l.upserted.str , t.findOne( { x : 2 } )._id.str , \"B2\" );\n assert.eq( 2 , t.find().count() , \"B3\" );\n+\n+// use the _id from the query for the insert\n+t.update({_id:3}, {$set: {a:'123'}}, true)\n+l = db.getLastErrorCmd();\n+assert( l.upserted , \"C1 - \" + tojson(l) );\n+assert.eq( l.upserted , 3 , \"C2 - \" + tojson(l) );\n+\n+// test with an embedded doc for the _id field\n+t.update({_id:{a:1}}, {$set: {a:123}}, true)\n+l = db.getLastErrorCmd();\n+assert( l.upserted , \"D1 - \" + tojson(l) );\n+assert.eq( l.upserted , {a:1} , \"D2 - \" + tojson(l) );\n+\n+// test with a range query\n+t.update({_id: {$gt:100}}, {$set: {a:123}}, true)\n+l = db.getLastErrorCmd();\n+assert( l.upserted , \"E1 - \" + tojson(l) );\n+assert.neq( l.upserted , 100 , \"E2 - \" + tojson(l) );\n+\n+// test with an _id query\n+t.update({_id: 1233}, {$set: {a:123}}, true)\n+l = db.getLastErrorCmd();\n+assert( l.upserted , \"F1 - \" + tojson(l) );\n+assert.eq( l.upserted , 1233 , \"F2 - \" + tojson(l) );\n+\n+// test with an embedded _id query\n+t.update({_id: {a:1, b:2}}, {$set: {a:123}}, true)\n+l = db.getLastErrorCmd();\n+assert( l.upserted , \"G1 - \" + tojson(l) );\n+assert.eq( l.upserted , {a:1, b:2} , \"G2 - \" + tojson(l) );\n+\n+// test with no _id inserted\n+db.createCollection(\"no_id\", {autoIndexId:false})\n+db.no_id.update({foo:1}, {$set:{a:1}}, true)\n+l = db.getLastErrorCmd();\n+assert.eq( l.upserted , undefined , \"H1 - \" + tojson(l) );\ndiff --git a/src/mongo/db/commands/find_and_modify.cpp b/src/mongo/db/commands/find_and_modify.cpp\nindex 0c18cc1..63b4c9f 100644\n--- a/src/mongo/db/commands/find_and_modify.cpp\n+++ b/src/mongo/db/commands/find_and_modify.cpp\n@@ -136,7 +136,9 @@ namespace mongo {\n \n             BSONObj doc;\n             \n+            LOG(0) << \"finding first doc based on query: \" << queryOriginal << \" in \" << ns;\n             bool found = Helpers::findOne( ns.c_str() , queryOriginal , doc );\n+            LOG(0) << \"found doc: \" << doc;\n \n             BSONObj queryModified = queryOriginal;\n             if ( found && doc[\"_id\"].type() && ! isSimpleIdQuery( queryOriginal ) ) {\n@@ -228,14 +230,20 @@ namespace mongo {\n \n                     UpdateResult res = mongo::update(request, &cc().curop()->debug());\n \n+                    LOG(0) << \"update result: \"  << res ;\n                     if ( returnNew ) {\n-                        if ( res.upserted.isSet() ) {\n-                            queryModified = BSON( \"_id\" << res.upserted );\n+                        if ( !res.upserted.isEmpty() ) {\n+                            BSONElement upsertedElem = res.upserted[kUpsertedFieldName];\n+                            LOG(0) << \"using new _id to get new doc: \"\n+                                   << upsertedElem;\n+                            queryModified = upsertedElem.wrap(\"_id\");\n                         }\n                         else if ( queryModified[\"_id\"].type() ) {\n                             // we do this so that if the update changes the fields, it still matches\n                             queryModified = queryModified[\"_id\"].wrap();\n                         }\n+\n+                        LOG(0) << \"using modified query to return the new doc: \" << queryModified;\n                         if ( ! Helpers::findOne( ns.c_str() , queryModified , doc ) ) {\n                             errmsg = str::stream() << \"can't find object after modification  \" \n                                                    << \" ns: \" << ns \n@@ -250,8 +258,9 @@ namespace mongo {\n                     BSONObjBuilder le( result.subobjStart( \"lastErrorObject\" ) );\n                     le.appendBool( \"updatedExisting\" , res.existing );\n                     le.appendNumber( \"n\" , res.numMatched );\n-                    if ( res.upserted.isSet() )\n-                        le.append( \"upserted\" , res.upserted );\n+                    if ( !res.upserted.isEmpty() ) {\n+                        le.append( res.upserted[kUpsertedFieldName] );\n+                    }\n                     le.done();\n                     \n                 }\n@@ -306,11 +315,14 @@ namespace mongo {\n                 }\n \n                 if (cmdObj[\"new\"].trueValue()) {\n-                    BSONElement _id = gle[\"upserted\"];\n-                    if (_id.eoo())\n-                        _id = origQuery[\"_id\"];\n-\n-                    out = db.findOne(ns, QUERY(\"_id\" << _id), fields);\n+                    BSONObjBuilder bob;\n+                    BSONElement _id = gle[kUpsertedFieldName];\n+                    if (!_id.eoo())\n+                        bob.appendAs(_id, \"_id\");\n+                    else\n+                        bob.appendAs(origQuery[\"_id\"], \"_id\");\n+\n+                    out = db.findOne(ns, bob.done(), fields);\n                 }\n \n             }\ndiff --git a/src/mongo/db/commands/write_commands/batch_executor.cpp b/src/mongo/db/commands/write_commands/batch_executor.cpp\nindex 3b10944..626a32a 100644\n--- a/src/mongo/db/commands/write_commands/batch_executor.cpp\n+++ b/src/mongo/db/commands/write_commands/batch_executor.cpp\n@@ -276,7 +276,7 @@ namespace mongo {\n \n         bool resExisting = false;\n         long long resNum = 0;\n-        OID resUpserted = OID();\n+        BSONObj resUpserted;\n         try {\n \n             const NamespaceString requestNs( ns );\n@@ -294,8 +294,8 @@ namespace mongo {\n             resNum = res.numMatched;\n             resUpserted = res.upserted;\n \n-            stats->numUpdated += !resUpserted.isSet() ? resNum : 0;\n-            stats->numUpserted += resUpserted.isSet() ? 1 : 0;\n+            stats->numUpdated += resUpserted.isEmpty() ? resNum : 0;\n+            stats->numUpserted += !resUpserted.isEmpty() ? 1 : 0;\n         }\n         catch ( const UserException& ex ) {\n             opDebug.exceptionInfo = ex.getInfo();\ndiff --git a/src/mongo/db/lasterror.cpp b/src/mongo/db/lasterror.cpp\nindex e239ac8..fd9129e 100644\n--- a/src/mongo/db/lasterror.cpp\n+++ b/src/mongo/db/lasterror.cpp\n@@ -77,9 +77,9 @@ namespace mongo {\n             b.append( \"code\" , code );\n         if ( updatedExisting != NotUpdate )\n             b.appendBool( \"updatedExisting\", updatedExisting == True );\n-        if ( upsertedId.isSet() )\n-            b.append( \"upserted\" , upsertedId );\n-\n+        if ( !upsertedId.isEmpty() ) {\n+            b.append( upsertedId[kUpsertedFieldName] );\n+        }\n         b.appendNumber( \"n\", nObjects );\n \n         return ! msg.empty();\ndiff --git a/src/mongo/db/lasterror.h b/src/mongo/db/lasterror.h\nindex 65c1a72..4a4e7b1 100644\n--- a/src/mongo/db/lasterror.h\n+++ b/src/mongo/db/lasterror.h\n@@ -20,6 +20,7 @@\n #include <boost/thread/tss.hpp>\n #include <string>\n \n+#include \"mongo/db/jsobj.h\"\n #include \"mongo/bson/oid.h\"\n #include \"mongo/util/log.h\"\n \n@@ -27,11 +28,14 @@ namespace mongo {\n     class BSONObjBuilder;\n     class Message;\n \n+    static const char kUpsertedFieldName[] = \"upserted\";\n+\n     struct LastError {\n         int code;\n         std::string msg;\n         enum UpdatedExistingType { NotUpdate, True, False } updatedExisting;\n-        OID upsertedId;\n+        // _id field value from inserted doc, returned as kUpsertedFieldName (above)\n+        BSONObj upsertedId;\n         OID writebackId; // this shouldn't get reset so that old GLE are handled\n         int writebackSince;\n         long long nObjects;\n@@ -48,11 +52,11 @@ namespace mongo {\n             code = _code;\n             msg = _msg;\n         }\n-        void recordUpdate( bool _updateObjects , long long _nObjects , OID _upsertedId ) {\n+        void recordUpdate( bool _updateObjects , long long _nObjects , BSONObj _upsertedId ) {\n             reset( true );\n             nObjects = _nObjects;\n             updatedExisting = _updateObjects ? True : False;\n-            if ( _upsertedId.isSet() )\n+            if ( _upsertedId.valid() && _upsertedId.hasField(kUpsertedFieldName) )\n                 upsertedId = _upsertedId;\n \n         }\n@@ -72,7 +76,7 @@ namespace mongo {\n             nPrev = 1;\n             valid = _valid;\n             disabled = false;\n-            upsertedId.clear();\n+            upsertedId = BSONObj();\n         }\n \n         /**\ndiff --git a/src/mongo/db/ops/update.cpp b/src/mongo/db/ops/update.cpp\nindex 2ada28b..c01eabc 100644\n--- a/src/mongo/db/ops/update.cpp\n+++ b/src/mongo/db/ops/update.cpp\n@@ -117,6 +117,7 @@ namespace mongo {\n \n     UpdateResult update(const UpdateRequest& request, OpDebug* opDebug, UpdateDriver* driver) {\n \n+        LOG(0) << \"processing update : \" << request;\n         const NamespaceString& nsString = request.getNamespaceString();\n \n         validateUpdate( nsString.ns().c_str(), request.getUpdates(), request.getQuery() );\ndiff --git a/src/mongo/db/ops/update_request.h b/src/mongo/db/ops/update_request.h\nindex c2dfb36..0eb5ffe 100644\n--- a/src/mongo/db/ops/update_request.h\n+++ b/src/mongo/db/ops/update_request.h\n@@ -32,9 +32,12 @@\n #include \"mongo/db/curop.h\"\n #include \"mongo/db/namespace_string.h\"\n #include \"mongo/db/query_plan_selection_policy.h\"\n+#include \"mongo/util/mongoutils/str.h\"\n \n namespace mongo {\n \n+    namespace str = mongoutils::str;\n+\n     class UpdateRequest {\n     public:\n         inline UpdateRequest(\n@@ -124,6 +127,17 @@ namespace mongo {\n             return _fromReplication;\n         }\n \n+        const std::string toString() const {\n+            return str::stream()\n+                        << \" query: \" << _query\n+                        << \" updated: \" << _updates\n+                        << \" god: \" << _god\n+                        << \" upsert: \" << _upsert\n+                        << \" multe: \" << _multi\n+                        << \" logToOplog: \" << _updateOpLog\n+                        << \" fromMigration: \" << _fromMigration\n+                        << \" fromReplications: \" << _fromReplication;\n+        }\n     private:\n \n         const NamespaceString& _nsString;\ndiff --git a/src/mongo/db/ops/update_result.h b/src/mongo/db/ops/update_result.h\nindex 7983788..9d42af1 100644\n--- a/src/mongo/db/ops/update_result.h\n+++ b/src/mongo/db/ops/update_result.h\n@@ -32,9 +32,12 @@\n #include \"mongo/db/curop.h\"\n #include \"mongo/db/namespace_string.h\"\n #include \"mongo/db/query_plan_selection_policy.h\"\n+#include \"mongo/util/mongoutils/str.h\"\n \n namespace mongo {\n \n+    namespace str = mongoutils::str;\n+\n     struct UpdateResult {\n \n         UpdateResult( bool existing_,\n@@ -45,10 +48,9 @@ namespace mongo {\n             , modifiers(modifiers_)\n             , numMatched(numMatched_) {\n \n-            upserted.clear();\n             BSONElement id = upsertedObject_[\"_id\"];\n-            if ( ! existing && numMatched == 1 && id.type() == jstOID ) {\n-                upserted = id.OID();\n+            if ( ! existing && numMatched == 1 && !id.eoo() ) {\n+                upserted = id.wrap(kUpsertedFieldName);\n             }\n         }\n \n@@ -63,7 +65,15 @@ namespace mongo {\n         const long long numMatched;\n \n         // if something was upserted, the new _id of the object\n-        OID upserted;\n+        BSONObj upserted;\n+\n+        const std::string toString() const {\n+            return str::stream()\n+                        << \" upserted: \" << upserted\n+                        << \" modifiers: \" << modifiers\n+                        << \" existing: \" << existing\n+                        << \" numMatched: \" << numMatched;\n+        }\n     };\n \n } // namespace mongo\n","summary":[{"filename":"jstests/find_and_modify4.js","additions":7,"deletions":7},{"filename":"jstests/upsert1.js","additions":41,"deletions":3},{"filename":"src/mongo/db/commands/find_and_modify.cpp","additions":21,"deletions":9},{"filename":"src/mongo/db/commands/write_commands/batch_executor.cpp","additions":3,"deletions":3},{"filename":"src/mongo/db/lasterror.cpp","additions":3,"deletions":3},{"filename":"src/mongo/db/lasterror.h","additions":8,"deletions":4},{"filename":"src/mongo/db/ops/update.cpp","additions":1,"deletions":0},{"filename":"src/mongo/db/ops/update_request.h","additions":14,"deletions":0},{"filename":"src/mongo/db/ops/update_result.h","additions":14,"deletions":4}]}}],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"525898bb3ff1227ca1000002"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["linux-32","rhel-57-64-bit"],"create_time":{"$date":"2013-10-12T00:32:59.233Z"},"desc":"SERVER-10992 SERVER-11130 test run","githash":"50682334073f0289d8700080a09299e6e061276c","patches":[{"name":"","githash":"50682334073f0289d8700080a09299e6e061276c","patch_set":{"patch":"diff --git a/src/SConscript.client b/src/SConscript.client\nindex 1690233..06c2645 100644\n--- a/src/SConscript.client\n+++ b/src/SConscript.client\n@@ -219,15 +219,14 @@ if buildShared:\n     # InstallVersionedLibrary support is only stable in SCons > 2.3.0, so if you add support\n     # here, be sure to add an EnsuredSconsVersion here as well.\n     sharedLibEnv = env.Clone()\n-    sharedLibEnv.AppendUnique(\n-        LIBS=mongoClientLibs + mongoClientSysLibDeps,\n-        # TODO: This currently causes the files for the libdep to get dragged into dependents\n-        # of this shared library, incorrectly. We need to patch up libdeps to treat shared\n-        # libraries as dependency terminals.\n-        LIBDEPS=mongoClientLibDeps)\n+    sharedLibEnv.AppendUnique(LIBS=mongoClientSysLibDeps)\n \n-    if linux:\n-        sharedLibEnv.AppendUnique(SHLINKFLAGS=[\"-Wl,--as-needed\", \"-Wl,-zdefs\"])\n+    # Attach the shim only if we are using the external libraries so that we pick up what\n+    # configure found for us.\n+    if use_system_version_of_library(\"boost\"):\n+        sharedLibEnv.AppendUnique(LIBDEPS=mongoClientLibDeps)\n+        if linux:\n+            sharedLibEnv.AppendUnique(SHLINKFLAGS=[\"-Wl,--as-needed\", \"-Wl,-zdefs\"])\n \n     if windows:\n         # Ignore warning LNK4102, which complains about exposing deleting destructors.\n@@ -238,7 +237,7 @@ if buildShared:\n         # SCons automatically looks for this file in the source list and passes the proper\n         # parameter to MS-LINK automatically.\n         clientObjects.append('mongoclient.def')\n-    \n+\n     mongoClientSharedLib = sharedLibEnv.SharedLibrary('mongoclient', clientObjects)\n \n     mongoClientSharedLibInstall = sharedLibEnv.Install(\n@@ -303,7 +302,7 @@ if buildShared:\n     sharedClientEnv.PrependUnique(\n         LIBS=['mongoclient'],\n         LIBPATH=[\"#/sharedclient\"],\n-        LIBDEPS=['$BUILD_DIR/third_party/shim_boost']\n+        LIBDEPS=mongoClientLibDeps,\n     )\n \n     # Deal with the different lookup models between regular UNIX and Darwin. For regular unix,\n","summary":[{"filename":"src/SConscript.client","additions":9,"deletions":10}]}}],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"525d5a463ff122435c000001"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["osx-108-cxx11-debug"],"create_time":{"$date":"2013-10-15T15:07:50.691Z"},"desc":"SERVER-11183 test run","githash":"9fcdfeb195c42e91a49e37212a65fea624d71c13","patches":[{"name":"","githash":"9fcdfeb195c42e91a49e37212a65fea624d71c13","patch_set":{"patch":"diff --git a/src/mongo/dbtests/perftests.cpp b/src/mongo/dbtests/perftests.cpp\nindex d1c1d02..66aba15 100644\n--- a/src/mongo/dbtests/perftests.cpp\n+++ b/src/mongo/dbtests/perftests.cpp\n@@ -1363,7 +1363,17 @@ namespace PerfTests {\n                 add< Throw< thr1 > >();\n                 add< Throw< thr2 > >();\n                 add< Throw< thr3 > >();\n+\n+#if !defined(__clang__) || !defined(MONGO_OPTIMIZED_BUILD) || (__clang_major__ > 3) || ((__clang_major__ == 3) && (__clang_minor__ > 2))\n+                // clang-3.2 (and earlier?) miscompiles this test when optimization is on (see\n+                // SERVER-9767 and SERVER-11183 for additional details, including a link to the\n+                // LLVM ticket and LLVM fix).\n+                //\n+                // TODO: We should consider requiring clang > 3.2 in our configure tests once\n+                // XCode 5 is ubiquitious.\n                 add< Throw< thr4 > >();\n+#endif\n+\n                 add< Timer >();\n                 add< Sleep0Ms >();\n #if defined(__USE_XOPEN2K)\n","summary":[{"filename":"src/mongo/dbtests/perftests.cpp","additions":10,"deletions":0}]}}],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"525d85c93ff122435c000002"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["osx-108-cxx11-debug"],"create_time":{"$date":"2013-10-15T18:13:29.821Z"},"desc":"SERVER-11183 test run 2","githash":"506fe5ad46b9a0d083af61f4e52a5726f2656949","patches":[{"name":"","githash":"506fe5ad46b9a0d083af61f4e52a5726f2656949","patch_set":{"patch":"diff --git a/src/mongo/dbtests/perftests.cpp b/src/mongo/dbtests/perftests.cpp\nindex d1c1d02..4081844 100644\n--- a/src/mongo/dbtests/perftests.cpp\n+++ b/src/mongo/dbtests/perftests.cpp\n@@ -1363,7 +1363,23 @@ namespace PerfTests {\n                 add< Throw< thr1 > >();\n                 add< Throw< thr2 > >();\n                 add< Throw< thr3 > >();\n+\n+#if !defined(__clang__) || !defined(MONGO_OPTIMIZED_BUILD)\n+                // clang-3.2 (and earlier?) miscompiles this test when optimization is on (see\n+                // SERVER-9767 and SERVER-11183 for additional details, including a link to the\n+                // LLVM ticket and LLVM fix).\n+                //\n+                // Ideally, the test above would also say\n+                // || (__clang_major__ > 3) || ((__clang_major__ == 3) && (__clang_minor__ > 2))\n+                // so that the test would still run on known good vesrions of clang; see\n+                // comments in SERVER-11183 for why that doesn't work.\n+                //\n+                // TODO: Remove this when we no longer need to support clang-3.2. We should\n+                // also consider requiring clang > 3.2 in our configure tests once XCode 5 is\n+                // ubiquitious.\n                 add< Throw< thr4 > >();\n+#endif\n+\n                 add< Timer >();\n                 add< Sleep0Ms >();\n #if defined(__USE_XOPEN2K)\n","summary":[{"filename":"src/mongo/dbtests/perftests.cpp","additions":16,"deletions":0}]}}],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"526157dc3ff1227116000005"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["osx-108"],"create_time":{"$date":"2013-10-18T15:46:36.728Z"},"desc":"MCI-832 test run","githash":"428be313f4ac309d792de049fbab966c19f02bb9","patches":[{"name":"","githash":"428be313f4ac309d792de049fbab966c19f02bb9","patch_set":{"patch":"diff --git a/SConstruct b/SConstruct\nindex b33acbd..5f33a58 100644\n--- a/SConstruct\n+++ b/SConstruct\n@@ -1226,9 +1226,11 @@ def doConfigure(myenv):\n     # This needs to happen before we check for libc++, since it affects whether libc++ is available.\n     if darwin and has_option('osx-version-min'):\n         min_version = get_option('osx-version-min')\n-        if not AddToCCFLAGSIfSupported(myenv, '-mmacosx-version-min=%s' % (min_version)):\n+        min_version_flag = '-mmacosx-version-min=%s' % (min_version)\n+        if not AddToCCFLAGSIfSupported(myenv, min_version_flag):\n             print( \"Can't set minimum OS X version with this compiler\" )\n             Exit(1)\n+        myenv.AppendUnique(LINKFLAGS=[min_version_flag])\n \n     if has_option('libc++'):\n         if not using_clang():\n","summary":[{"filename":"SConstruct","additions":3,"deletions":1}]}}],"tasks":[],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"5267cc2a3ff1227207000001"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["linux-64"],"create_time":{"$date":"2013-10-23T13:16:26.335Z"},"desc":"linux-64","githash":"3b87e21f115188af7b47e7c50486133450a5d029","patches":[{"name":"","githash":"3b87e21f115188af7b47e7c50486133450a5d029","patch_set":{"patch":"diff --git a/jstests/sharding/hash_shard_unique_compound.js b/jstests/sharding/hash_shard_unique_compound.js\nnew file mode 100644\nindex 0000000..42f6cc9\n--- /dev/null\n+++ b/jstests/sharding/hash_shard_unique_compound.js\n@@ -0,0 +1,50 @@\n+// Basic test of sharding with a hashed shard key and other unique index\n+// Does 2 things and checks for consistent error:\n+//  1.) shard collection on hashed \"a\", ensure unique index {a:1, b:1}\n+//  2.) reverse order\n+\n+var s = new ShardingTest( { name : jsTestName() , shards : 3 , mongos : 1, verbose : 1 } );\n+var dbname = \"test\";\n+var coll = \"foo\";\n+var ns = dbname + \".\" + coll;\n+var db = s.getDB( dbname );\n+var t = db.getCollection( coll );\n+\n+// Enable sharding on DB\n+var res = db.adminCommand( { enablesharding : dbname } );\n+\n+// for simplicity start by turning off balancer\n+var res = s.stopBalancer();\n+\n+// shard a fresh collection using a hashed shard key\n+t.drop();\n+var res = db.adminCommand( { shardcollection : ns , key : { a : \"hashed\" } } );\n+assert.eq( res.ok , 1 , \"shardcollection didn't work -- \" + tojson(res));\n+db.printShardingStatus();\n+\n+// Create unique index\n+t.ensureIndex({a:1, b:1}, {unique:true})\n+var gle = db.getLastErrorObj();\n+assert(!gle.err, \"unique index failed --\" + tojson(gle))\n+\n+print(\"------ indexes -------\")\n+printjson(t.getIndexes());\n+\n+\n+// Second Part\n+print(\"------ dropping sharded collection -------\")\n+t.drop();\n+\n+//Create unique index\n+t.ensureIndex({a:1, b:1}, {unique:true})\n+var gle = db.getLastErrorObj();\n+assert.eq(gle.err, null, \"unique index failed\")\n+\n+// shard a fresh collection using a hashed shard key\n+var res = db.adminCommand( { shardcollection : ns , key : { a : \"hashed\" } } );\n+assert.eq( res.ok , 1 , \"shardcollection didn't worked 2 -- \" + tojson(res));\n+db.printShardingStatus();\n+print(\"------ indexes 2-------\")\n+printjson(t.getIndexes());\n+\n+s.stop()\ndiff --git a/src/mongo/db/keypattern.h b/src/mongo/db/keypattern.h\nindex 7e79f7f..25331e7 100644\n--- a/src/mongo/db/keypattern.h\n+++ b/src/mongo/db/keypattern.h\n@@ -89,7 +89,7 @@ namespace mongo {\n          * the (potentially) compound key described by 'other'\n          */\n         bool isPrefixOf( const KeyPattern& other ) const {\n-            return _pattern.isPrefixOf( other.toBSON() );\n+            return _pattern.isFieldNamePrefixOf( other.toBSON() );\n         }\n \n         /**\ndiff --git a/src/mongo/s/shardkey.cpp b/src/mongo/s/shardkey.cpp\nindex afd91ea..56eb805 100644\n--- a/src/mongo/s/shardkey.cpp\n+++ b/src/mongo/s/shardkey.cpp\n@@ -72,16 +72,12 @@ namespace mongo {\n         return true;\n     }\n \n-    bool ShardKeyPattern::isPrefixOf( const KeyPattern& otherPattern ) const {\n-        return pattern.isPrefixOf( otherPattern );\n-    }\n-\n     bool ShardKeyPattern::isUniqueIndexCompatible( const KeyPattern& uniqueIndexPattern ) const {\n         if ( ! uniqueIndexPattern.toBSON().isEmpty() &&\n              str::equals( uniqueIndexPattern.toBSON().firstElementFieldName(), \"_id\" ) ){\n             return true;\n         }\n-        return pattern.toBSON().isFieldNamePrefixOf( uniqueIndexPattern.toBSON() );\n+        return pattern.isPrefixOf( uniqueIndexPattern );\n     }\n \n     string ShardKeyPattern::toString() const {\ndiff --git a/src/mongo/s/shardkey.h b/src/mongo/s/shardkey.h\nindex b3e1c46..c9de179 100644\n--- a/src/mongo/s/shardkey.h\n+++ b/src/mongo/s/shardkey.h\n@@ -98,12 +98,6 @@ namespace mongo {\n \n         /**\n          * @return\n-         * true if 'this' is a prefix (not necessarily contained) of 'otherPattern'.\n-         */\n-        bool isPrefixOf( const KeyPattern& otherPattern ) const;\n-\n-        /**\n-         * @return\n          * true if this shard key is compatible with a unique index on 'uniqueIndexPattern'.\n          *      Primarily this just checks whether 'this' is a prefix of 'uniqueIndexPattern',\n          *      However it does not need to be an exact syntactic prefix due to \"hashed\"\ndiff --git a/src/mongo/s/strategy_shard.cpp b/src/mongo/s/strategy_shard.cpp\nindex de5899c..5625583 100644\n--- a/src/mongo/s/strategy_shard.cpp\n+++ b/src/mongo/s/strategy_shard.cpp\n@@ -1343,7 +1343,7 @@ namespace mongo {\n                                  \" key: \" + o[\"key\"].embeddedObjectUserCheck().toString() ,\n                                  IndexDetails::isIdIndexPattern( newIndexKey ) ||\n                                  ! o[\"unique\"].trueValue() ||\n-                                 r.getConfig()->getChunkManager( ns )->getShardKey().isPrefixOf( newIndexKey ) );\n+                                 r.getConfig()->getChunkManager( ns )->getShardKey().isUniqueIndexCompatible( newIndexKey ) );\n \n                         ChunkManagerPtr cm = r.getConfig()->getChunkManager( ns );\n                         verify( cm );\n","summary":[{"filename":"jstests/sharding/hash_shard_unique_compound.js","additions":50,"deletions":0},{"filename":"src/mongo/db/keypattern.h","additions":1,"deletions":1},{"filename":"src/mongo/s/shardkey.cpp","additions":1,"deletions":5},{"filename":"src/mongo/s/shardkey.h","additions":0,"deletions":6},{"filename":"src/mongo/s/strategy_shard.cpp","additions":1,"deletions":1}]}}],"tasks":[],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"526877833ff1225852000005"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["linux-64"],"create_time":{"$date":"2013-10-24T01:27:31.226Z"},"desc":"linux-64","githash":"ec409bbf8271fa5e10284961fe9106c28cbb6023","patches":[{"name":"","githash":"ec409bbf8271fa5e10284961fe9106c28cbb6023","patch_set":{"patch":"diff --git a/src/mongo/db/mongod_options_test.cpp b/src/mongo/db/mongod_options_test.cpp\nindex 2ec72ca..5b33eb0 100644\n--- a/src/mongo/db/mongod_options_test.cpp\n+++ b/src/mongo/db/mongod_options_test.cpp\n@@ -1155,6 +1155,18 @@ namespace {\n                 ASSERT_EQUALS(iterator->_sources, moe::SourceAll);\n             }\n #endif\n+#if defined(__linux__)\n+            else if (iterator->_dottedName == \"shutdown\") {\n+                ASSERT_EQUALS(iterator->_singleName, \"shutdown\");\n+                ASSERT_EQUALS(iterator->_type, moe::Switch);\n+                ASSERT_EQUALS(iterator->_description, \"kill a running server (for init scripts)\");\n+                ASSERT_EQUALS(iterator->_isVisible, true);\n+                ASSERT_TRUE(iterator->_default.isEmpty());\n+                ASSERT_TRUE(iterator->_implicit.isEmpty());\n+                ASSERT_EQUALS(iterator->_isComposing, false);\n+                ASSERT_EQUALS(iterator->_sources, moe::SourceAll);\n+            }\n+#endif\n             else {\n                 ::mongo::StringBuilder sb;\n                 sb << \"Found extra option: \" << iterator->_dottedName <<\n","summary":[{"filename":"src/mongo/db/mongod_options_test.cpp","additions":12,"deletions":0}]}}],"tasks":[],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"5269746c3ff1223136000003"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["cxx11-ubuntu1204-64","enterprise-linux-64-amazon-ami","enterprise-rhel-57-64-bit","enterprise-rhel-62-64-bit","enterprise-suse11-64","enterprise-ubuntu1204-64","enterprise-windows-64","linux-32","linux-32-debug","linux-64","linux-64-debug","linux-64-debug-duroff","linux-64-duroff","osx-108","osx-108-cxx11-debug","osx-108-debug","osx-108-dur-off","rhel-57-64-bit","solaris-64-bit","windows-32","windows-64","windows-64-2k8","windows-64-2k8-debug","windows-64-debug"],"create_time":{"$date":"2013-10-24T19:26:36.161Z"},"desc":"","githash":"bc05262b903baafd4a286008ab3323172d8c3275","patches":[{"name":"","githash":"bc05262b903baafd4a286008ab3323172d8c3275","patch_set":{"patch":"diff --git a/jstests/ssl/ssl_fips.js b/jstests/ssl/ssl_fips.js\nindex 76118a7..7b2da1a 100644\n--- a/jstests/ssl/ssl_fips.js\n+++ b/jstests/ssl/ssl_fips.js\n@@ -1,5 +1,4 @@\n // Test mongod start with FIPS mode enabled\n-if (0) { // SERVER-11005\n ports = allocatePorts(1);\n port1 = ports[0];\n var baseName = \"jstests_ssl_ssl_fips\";\n@@ -10,11 +9,21 @@ var md = startMongod(\"--port\", port1, \"--dbpath\",\n                      \"--sslPEMKeyFile\", \"jstests/libs/server.pem\",\n                      \"--sslFIPSMode\");\n \n-var mongo = runMongoProgram(\"mongo\", \"--port\", port1, \"--ssl\",\n-                            \"--sslPEMKeyFile\", \"jstests/libs/client.pem\",\n-                            \"--sslFIPSMode\",\n-                            \"--eval\", \";\");\n+// if mongod didn't start properly\n+if (md != 0) {\n+    print(\"mongod failed to start, checking for FIPS support\");\n+    assert(rawMongoProgramOutput().match(\n+            /this version of mongodb was not compiled with FIPS support/));\n+}\n+else {\n+    // try connecting shell\n+    var mongo = runMongoProgram(\"mongo\", \"--port\", port1, \"--ssl\",\n+                                \"--sslPEMKeyFile\", \"jstests/libs/client.pem\",\n+                                \"--sslFIPSMode\",\n+                                \"--eval\", \";\");\n \n-// 0 is the exit code for success\n-assert(mongo==0);\n+    // 0 is the exit code for success\n+    assert(mongo==0);\n+    // kill mongod\n+    stopMongod(port1, 9);\n }\n","summary":[{"filename":"jstests/ssl/ssl_fips.js","additions":16,"deletions":7}]}}],"tasks":["ssl"],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"526b12693ff1226402000007"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["osx-108","osx-108-debug","osx-108-dur-off","osx-108-cxx11-debug"],"create_time":{"$date":"2013-10-26T00:52:57.361Z"},"desc":"Empty patch to run a lot of osx tasks","githash":"78a5cc81af2209e10e1357a41e02f1689b60ef1e","patches":[{"name":"","githash":"78a5cc81af2209e10e1357a41e02f1689b60ef1e","patch_set":{"patch":"diff --git a/README b/README\nindex 3dac687..b0f8a3c 100644\n--- a/README\n+++ b/README\n@@ -1,5 +1,6 @@\n MongoDB README\r\n \r\n+\r\n Welcome to MongoDB!\r\n \r\n COMPONENTS\r\n","summary":[{"filename":"README","additions":1,"deletions":0}]}}],"tasks":[],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"52b705e73ff1220a97000001"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["linux-32-debug","linux-64-debug","linux-64-debug-duroff","osx-108-debug"],"create_time":{"$date":"2013-12-22T15:31:51.621Z"},"desc":"SERVER-12189 test","githash":"a36903ef715cc962a254904e56b0ac1b7efd922f","patches":[{"name":"","githash":"a36903ef715cc962a254904e56b0ac1b7efd922f","patch_set":{"patch":"diff --git a/SConstruct b/SConstruct\nindex 872316a..ba14eeb 100644\n--- a/SConstruct\n+++ b/SConstruct\n@@ -1229,6 +1229,7 @@ def doConfigure(myenv):\n             Exit(1)\n         myenv.AppendUnique(LINKFLAGS=[min_version_flag])\n \n+    usingLibStdCxx = False\n     if has_option('libc++'):\n         if not using_clang():\n             print( 'libc++ is currently only supported for clang')\n@@ -1238,6 +1239,34 @@ def doConfigure(myenv):\n         else:\n             print( 'libc++ requested, but compiler does not support -stdlib=libc++' )\n             Exit(1)\n+    else:\n+        def CheckLibStdCxx(context):\n+            test_body = \"\"\"\n+            #include <vector>\n+            #if !defined(__GLIBCXX__)\n+            #error\n+            #endif\n+            \"\"\"\n+\n+            context.Message('Checking if we are using libstdc++... ')\n+            ret = context.TryCompile(textwrap.dedent(test_body), \".cpp\")\n+            context.Result(ret)\n+            return ret\n+\n+        conf = Configure(myenv, help=False, custom_tests = {\n+            'CheckLibStdCxx' : CheckLibStdCxx,\n+        })\n+        usingLibStdCxx = conf.CheckLibStdCxx()\n+        conf.Finish()\n+\n+    # If we are uinsg libstdc++ and this is a debug build, turn on the debugging features in\n+    # the library.\n+    if usingLibStdCxx and debugBuild:\n+        # We can't do this if we are using any system C++ libraries.\n+        if (not use_system_version_of_library(\"tcmalloc\") and\n+            not use_system_version_of_library(\"boost\") and\n+            not use_system_version_of_library(\"v8\")):\n+            myenv.Append(CPPDEFINES=[\"_GLIBCXX_DEBUG\"]);\n \n     # Check to see if we are trying to use an outdated libstdc++ in C++11 mode. This is\n     # primarly to help people using clang in C++11 mode on OS X but forgetting to use\n@@ -1245,7 +1274,7 @@ def doConfigure(myenv):\n     # is not workable. Instead, we switch on the fact that std::is_nothrow_constructible wasn't\n     # introduced until libstdc++ 4.6.0. Earlier versions of libstdc++ than 4.6 are unlikely to\n     # work well anyway.\n-    if has_option('c++11') and not has_option('libc++'):\n+    if usingLibStdCxx and has_option('c++11'):\n \n         def CheckModernLibStdCxx(context):\n \n","summary":[{"filename":"SConstruct","additions":30,"deletions":1}]}}],"tasks":["aggregation","aggregation_auth","auth","client","client_auth","clone","clone_auth","core","core_auth","disk","disk_auth","durability","durability_auth","failpoints","failpoints_auth","js","js_auth","js_small_oplog","jsCore","jsCore_auth","jsCore_small_oplog","mongo-perf","mongosTest","mongosTest_auth","multiversion","parallel","qa_repo_multiversion_tests","qa_repo_tests","replicasets","replicasets_auth","replication","replication_auth","sharding","sharding_auth","slow_nightly_tests","slow_weekly_tests","ssl","sslSpecial","tool","tool_auth"],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"52a630633ff1227909000021"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["osx-108"],"create_time":{"$date":"2013-12-09T21:04:35.417Z"},"desc":"testtest","githash":"ea1bcc2beb6638034c1c811042d399f1b92e5cd2","patches":[{"name":"","githash":"ea1bcc2beb6638034c1c811042d399f1b92e5cd2","patch_set":{"patch":"diff --git a/README b/README\nindex 3dac687..f35e2e1 100644\n--- a/README\n+++ b/README\n@@ -1,4 +1,4 @@\n-MongoDB README\n+dsfjhsadjlkfhMongoDB README\n \n Welcome to MongoDB!\n \n","summary":[{"filename":"superloooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooonnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggg name","additions":1,"deletions":1}]}}],"tasks":[],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"52617db33ff1224188000001"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["cxx11-ubuntu1204-64","enterprise-linux-64-amazon-ami","enterprise-rhel-57-64-bit","enterprise-rhel-62-64-bit","enterprise-suse11-64","enterprise-ubuntu1204-64","enterprise-windows-64","linux-32","linux-32-debug","linux-64","linux-64-debug","linux-64-debug-duroff","linux-64-duroff","osx-108","osx-108-cxx11-debug","osx-108-debug","osx-108-dur-off","rhel-57-64-bit","solaris-64-bit","windows-32","windows-64","windows-64-2k8","windows-64-2k8-debug","windows-64-debug"],"create_time":{"$date":"2013-10-18T18:28:03.253Z"},"desc":"work from code freeze","githash":"363c19f1a8b14398128d81ba7a6db7de058298b0","module_patches":[{"name":"enterprise","githash":"f6b84f931571284f5316fcc145788a82089485e0","patch_set":{"patch":"diff --git a/src/audit/audit_indexes_collections_databases.cpp b/src/audit/audit_indexes_collections_databases.cpp\nindex 79b23e5..cf4f0b2 100644\n--- a/src/audit/audit_indexes_collections_databases.cpp\n+++ b/src/audit/audit_indexes_collections_databases.cpp\n@@ -39,7 +39,7 @@ namespace audit {\n     std::ostream& CreateIndexEvent::putTextDescription(std::ostream& os) const {\n         os << \"Created index \" << _indexname\n            << \" on \" << _nsname\n-           << \" as \" << _indexSpec << '.';\n+           << \" as \" << *_indexSpec << '.';\n         return os;\n     }\n \ndiff --git a/src/audit/audit_user_management.cpp b/src/audit/audit_user_management.cpp\nindex 0a21976..fcf62fe 100644\n--- a/src/audit/audit_user_management.cpp\n+++ b/src/audit/audit_user_management.cpp\n@@ -218,15 +218,17 @@ namespace audit {\n             os << \" with customData \" << *_customData << ',';\n         }\n         bool first = true;\n-        for (std::vector<User::RoleData>::const_iterator role = _roles->begin();\n-                    role != _roles->end();\n-                    role++) {\n-            if (first) {\n-                os << \" with the following roles: \" << role->name;\n-                first = false;\n-            }\n-            else {\n-               os << \", \" << role->name;\n+        if (_roles) {\n+            for (std::vector<User::RoleData>::const_iterator role = _roles->begin();\n+                        role != _roles->end();\n+                        role++) {\n+                if (first) {\n+                    os << \" with the following roles: \" << role->name;\n+                    first = false;\n+                }\n+                else {\n+                   os << \", \" << role->name;\n+                }\n             }\n         }\n         os << '.';\n","summary":[{"filename":"src/audit/audit_indexes_collections_databases.cpp","additions":1,"deletions":1},{"filename":"src/audit/audit_user_management.cpp","additions":11,"deletions":9}]}}],"patches":[{"name":"","githash":"363c19f1a8b14398128d81ba7a6db7de058298b0","patch_set":{"patch":"diff --git a/jstests/slowNightly/ttl1.js b/jstests/slowNightly/ttl1.js\nindex f795d8b..50dae56 100644\n--- a/jstests/slowNightly/ttl1.js\n+++ b/jstests/slowNightly/ttl1.js\n@@ -1,21 +1,33 @@\n /**\n  * Part 1: Simple test of TTL.  Create a new collection with 24 docs, with timestamps at one hour\n  *         intervals, from now-minus-23 hours ago until now.  Also add some docs with non-date\n- *         values.  Then create a TTL index that expires all docs older than ~5.5 hours (20000\n- *         seconds).  Wait 70 seconds (TTL monitor runs every 60) and check that 18 docs deleted.\n- * Part 2: Add a second TTL index on an identical field. The second index expires docs older than\n+ *         values.  Then create a TTL index that expires all docs older than a string. Wait 70\n+ *         seconds (TTL monitor runs every 60) and check that no documents were deleted.\n+ * Part 2: Add a second TTL index that expires all docs older than ~5.5 hours (20000\n+ *         seconds).  Wait 70 seconds and check that 18 docs deleted.\n+ * Part 3: Add a third TTL index on an identical field. The second index expires docs older than\n  *         ~2.8 hours (10000 seconds). Wait 70 seconds and check that 3 more docs deleted.\n  */\n \n+assertEntryMatches = function(array, regex) {\n+    var found = false;\n+    for (i=0; i<array.length; i++) {\n+        if (regex.test(array[i])) {\n+             found = true;\n+        }\n+    }\n+    assert(found,\n+           \"The regex: \" + regex + \" did not match any entries in the array: \" + array.join('\\n'));\n+}\n // Part 1\n var t = db.ttl1;\n t.drop();\n \n var now = (new Date()).getTime();\n \n-for ( i=0; i<24; i++ ){\n-    var past = new Date( now - ( 3600 * 1000 * i ) );\n-    t.insert( { x : past , y : past } );\n+for (i=0; i<24; i++) {\n+    var past = new Date(now - (3600 * 1000 * i));\n+    t.insert({x: past, y: past, z: past});\n }\n t.insert( { a : 1 } )     //no x value\n t.insert( { x: null } )   //non-date value\n@@ -27,6 +39,18 @@ db.getLastError();\n \n assert.eq( 30 , t.count() );\n \n+t.ensureIndex( { z : 1 } , { expireAfterSeconds : \"20000\" } );\n+\n+sleep(70 * 1000);\n+\n+assert.eq(t.count(), 30);\n+\n+var loggedWarning = false;\n+var log = db.adminCommand({getLog: \"global\"}).log;\n+var msg = RegExp(\"ttl indexes require the expireAfterSeconds\" +\n+                 \" field to be numeric but received a type of:\");\n+assertEntryMatches(log, msg);\n+// Part 2\n t.ensureIndex( { x : 1 } , { expireAfterSeconds : 20000 } );\n \n assert.soon( \n@@ -41,7 +65,7 @@ assert.eq( 12 , t.count() );\n assert.lte( 18, db.serverStatus().metrics.ttl.deletedDocuments );\n assert.lte( 1, db.serverStatus().metrics.ttl.passes );\n \n-// Part 2\n+// Part 3\n t.ensureIndex( { y : 1 } , { expireAfterSeconds : 10000 } );\n \n assert.soon(\ndiff --git a/src/mongo/db/index_rebuilder.cpp b/src/mongo/db/index_rebuilder.cpp\nindex 6f3edbe..430ec1c 100644\n--- a/src/mongo/db/index_rebuilder.cpp\n+++ b/src/mongo/db/index_rebuilder.cpp\n@@ -54,27 +54,21 @@ namespace mongo {\n         std::vector<std::string> dbNames;\n         getDatabaseNames(dbNames);\n \n-        std::vector<std::string> nsToCheck;\n         try {\n-            for (std::vector<std::string>::const_iterator it = dbNames.begin();\n-                 it < dbNames.end();\n-                 it++) {\n-                const std::string systemNS = *it + \".system.namespaces\";\n-                DBDirectClient cli;\n-                scoped_ptr<DBClientCursor> cursor(cli.query(systemNS, Query()));\n-\n-                // This depends on system.namespaces not changing while we iterate\n-                while (cursor->more()) {\n-                    BSONObj nsDoc = cursor->nextSafe();\n-                    nsToCheck.push_back(nsDoc[\"name\"].valuestrsafe());\n-                }\n+            std::list<std::string> collNames;\n+            for (std::vector<std::string>::const_iterator dbName = dbNames.begin();\n+                 dbName < dbNames.end();\n+                 dbName++) {\n+                NamespaceIndex nsi(storageGlobalParams.dbpath, *dbName);\n+\n+                nsi.getNamespaces(collNames, /* onlyCollections */ true);\n             }\n             {\n                 boost::unique_lock<boost::mutex> lk(ReplSet::rss.mtx);\n                 ReplSet::rss.indexRebuildDone = true;\n                 ReplSet::rss.cond.notify_all();\n             }\n-            checkNS(nsToCheck);\n+            checkNS(collNames);\n         }\n         catch (const DBException&) {\n             warning() << \"index rebuilding did not complete\" << endl;\n@@ -87,9 +81,9 @@ namespace mongo {\n         LOG(1) << \"checking complete\" << endl;\n     }\n \n-    void IndexRebuilder::checkNS(const std::vector<std::string>& nsToCheck) {\n+    void IndexRebuilder::checkNS(const std::list<std::string>& nsToCheck) {\n         bool firstTime = true;\n-        for (std::vector<std::string>::const_iterator it = nsToCheck.begin();\n+        for (std::list<std::string>::const_iterator it = nsToCheck.begin();\n                 it != nsToCheck.end();\n                 ++it) {\n             // This write lock is held throughout the index building process\ndiff --git a/src/mongo/db/index_rebuilder.h b/src/mongo/db/index_rebuilder.h\nindex 08f10f7..110736f 100644\n--- a/src/mongo/db/index_rebuilder.h\n+++ b/src/mongo/db/index_rebuilder.h\n@@ -44,10 +44,10 @@ namespace mongo {\n \n     private:\n         /**\n-         * Check each collection in the passed in vector to see if it has any in-progress index\n+         * Check each collection in the passed in list to see if it has any in-progress index\n          * builds that need to be retried.  If so, calls retryIndexBuild.\n          */\n-        void checkNS(const std::vector<std::string>& nsToCheck);\n+        void checkNS(const std::list<std::string>& nsToCheck);\n \n         /**\n          * Actually retry an index build on a given namespace.\ndiff --git a/src/mongo/db/repl/rs.cpp b/src/mongo/db/repl/rs.cpp\nindex b67cf17..a096f78 100644\n--- a/src/mongo/db/repl/rs.cpp\n+++ b/src/mongo/db/repl/rs.cpp\n@@ -644,21 +644,11 @@ namespace {\n         // this is a shortcut for simple changes\n         if( additive ) {\n             log() << \"replSet info : additive change to configuration\" << rsLog;\n-            for( list<ReplSetConfig::MemberCfg*>::const_iterator i = newOnes.begin(); i != newOnes.end(); i++ ) {\n-                ReplSetConfig::MemberCfg *m = *i;\n-                Member *mi = new Member(m->h, m->_id, m, false);\n-\n-                /** we will indicate that new members are up() initially so that we don't relinquish our\n-                    primary state because we can't (transiently) see a majority.  they should be up as we\n-                    check that new members are up before getting here on reconfig anyway.\n-                    */\n-                mi->get_hbinfo().health = 0.1;\n-\n-                _members.push(mi);\n-                startHealthTaskFor(mi);\n-            }\n-\n             if (updateConfigs) {\n+                // we have new configs for existing members, so we need to repopulate _members\n+                // with the most recent configs\n+                _members.orphanAll();\n+\n                 // for logging\n                 string members = \"\";\n \n@@ -684,6 +674,22 @@ namespace {\n                 }\n             }\n \n+            // add any new members\n+            for (list<ReplSetConfig::MemberCfg*>::const_iterator i = newOnes.begin();\n+                    i != newOnes.end();\n+                    i++) {\n+                ReplSetConfig::MemberCfg *m = *i;\n+                Member *mi = new Member(m->h, m->_id, m, false);\n+\n+                // we will indicate that new members are up() initially so that we don't relinquish\n+                // our primary state because we can't (transiently) see a majority. they should be\n+                // up as we check that new members are up before getting here on reconfig anyway.\n+                mi->get_hbinfo().health = 0.1;\n+\n+                _members.push(mi);\n+                startHealthTaskFor(mi);\n+            }\n+\n             // if we aren't creating new members, we may have to update the\n             // groups for the current ones\n             _cfg->updateMembers(_members);\ndiff --git a/src/mongo/db/repl/rs_sync.cpp b/src/mongo/db/repl/rs_sync.cpp\nindex bfa5442..f244003 100644\n--- a/src/mongo/db/repl/rs_sync.cpp\n+++ b/src/mongo/db/repl/rs_sync.cpp\n@@ -258,7 +258,7 @@ namespace replset {\n         \n         std::vector< std::vector<BSONObj> > writerVectors(theReplSet->replWriterThreadCount);\n         fillWriterVectors(ops, &writerVectors);\n-        LOG(1) << \"replication batch size is \" << ops.size() << endl;\n+        LOG(2) << \"replication batch size is \" << ops.size() << endl;\n         // We must grab this because we're going to grab write locks later.\n         // We hold this mutex the entire time we're writing; it doesn't matter\n         // because all readers are blocked anyway.\ndiff --git a/src/mongo/db/server_options.cpp b/src/mongo/db/server_options.cpp\nindex bbd60e8..46deb38 100644\n--- a/src/mongo/db/server_options.cpp\n+++ b/src/mongo/db/server_options.cpp\n@@ -34,6 +34,7 @@\n #define SYSLOG_NAMES\n #include <syslog.h>\n #endif\n+#include <boost/filesystem.hpp>\n \n #include \"mongo/base/status.h\"\n #include \"mongo/bson/util/builder.h\"\n@@ -586,7 +587,8 @@ namespace {\n         }\n \n         if (params.count(\"keyFile\")) {\n-            serverGlobalParams.keyFile = params[\"keyFile\"].as<string>();\n+            serverGlobalParams.keyFile = boost::filesystem::absolute(\n+                                            params[\"keyFile\"].as<string>()).generic_string();\n         }\n \n         if ( params.count(\"pidfilepath\")) {\ndiff --git a/src/mongo/db/structure/collection_info_cache.cpp b/src/mongo/db/structure/collection_info_cache.cpp\nindex 8643446..7115384 100644\n--- a/src/mongo/db/structure/collection_info_cache.cpp\n+++ b/src/mongo/db/structure/collection_info_cache.cpp\n@@ -42,8 +42,10 @@\n namespace mongo {\n \n     CollectionInfoCache::CollectionInfoCache( Collection* collection )\n-        : _collection( collection ), _qcCacheMutex( \"_qcCacheMutex\" ) {\n-    }\n+        : _collection( collection ),\n+          _keysComputed( false ),\n+          _qcCacheMutex( \"_qcCacheMutex\" ),\n+          _qcWriteCount( 0 ) {}\n \n     void CollectionInfoCache::reset() {\n         Lock::assertWriteLocked( _collection->ns().ns() );\ndiff --git a/src/mongo/db/ttl.cpp b/src/mongo/db/ttl.cpp\nindex 88d83fe..15d5dbe 100644\n--- a/src/mongo/db/ttl.cpp\n+++ b/src/mongo/db/ttl.cpp\n@@ -92,6 +92,12 @@ namespace mongo {\n                     error() << \"key for ttl index can only have 1 field\" << endl;\n                     continue;\n                 }\n+                if (!idx[secondsExpireField].isNumber()) {\n+                    log() << \"ttl indexes require the \" << secondsExpireField << \" field to be \"\n+                          << \"numeric but received a type of: \"\n+                          << typeName(idx[secondsExpireField].type());\n+                    continue;\n+                }\n \n                 BSONObj query;\n                 {\n","summary":[{"filename":"jstests/slowNightly/ttl1.js","additions":31,"deletions":7},{"filename":"src/mongo/db/index_rebuilder.cpp","additions":10,"deletions":16},{"filename":"src/mongo/db/index_rebuilder.h","additions":2,"deletions":2},{"filename":"src/mongo/db/repl/rs.cpp","additions":20,"deletions":14},{"filename":"src/mongo/db/repl/rs_sync.cpp","additions":1,"deletions":1},{"filename":"src/mongo/db/server_options.cpp","additions":3,"deletions":1},{"filename":"src/mongo/db/structure/collection_info_cache.cpp","additions":4,"deletions":2},{"filename":"src/mongo/db/ttl.cpp","additions":6,"deletions":0}]}}],"tasks":["slow_nightly_tests","core","core_auth","failpoints","failpoints_auth","disk","disk_auth","tool","tool_auth","auth","client","client_auth","js","js_auth","js_small_oplog","replicasets","replicasets_auth","durability","durability_auth","mongosTest","mongosTest_auth","sharding","sharding_auth","replication","replication_auth","clone","clone_auth","parallel","aggregation","aggregation_auth","slow_weekly_tests","ssl","mongo-perf"],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"52653f463ff1222a2f000001"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["cxx11-ubuntu1204-64","enterprise-linux-64-amazon-ami","enterprise-rhel-57-64-bit","enterprise-rhel-62-64-bit","enterprise-suse11-64","enterprise-ubuntu1204-64","enterprise-windows-64","linux-32","linux-32-debug","linux-64","linux-64-debug","linux-64-debug-duroff","linux-64-duroff","osx-108","osx-108-cxx11-debug","osx-108-debug","osx-108-dur-off","rhel-57-64-bit","solaris-64-bit","windows-32","windows-64","windows-64-2k8","windows-64-2k8-debug","windows-64-debug"],"create_time":{"$date":"2013-10-21T14:50:46.251Z"},"desc":"","githash":"04c63390531b22857bd8110761b5cf631278f9b6","module_patches":[{"name":"enterprise","githash":"f6b84f931571284f5316fcc145788a82089485e0","patch_set":{"patch":"diff --git a/src/audit/audit_indexes_collections_databases.cpp b/src/audit/audit_indexes_collections_databases.cpp\nindex 79b23e5..cf4f0b2 100644\n--- a/src/audit/audit_indexes_collections_databases.cpp\n+++ b/src/audit/audit_indexes_collections_databases.cpp\n@@ -39,7 +39,7 @@ namespace audit {\n     std::ostream& CreateIndexEvent::putTextDescription(std::ostream& os) const {\n         os << \"Created index \" << _indexname\n            << \" on \" << _nsname\n-           << \" as \" << _indexSpec << '.';\n+           << \" as \" << *_indexSpec << '.';\n         return os;\n     }\n \ndiff --git a/src/audit/audit_user_management.cpp b/src/audit/audit_user_management.cpp\nindex 0a21976..fcf62fe 100644\n--- a/src/audit/audit_user_management.cpp\n+++ b/src/audit/audit_user_management.cpp\n@@ -218,15 +218,17 @@ namespace audit {\n             os << \" with customData \" << *_customData << ',';\n         }\n         bool first = true;\n-        for (std::vector<User::RoleData>::const_iterator role = _roles->begin();\n-                    role != _roles->end();\n-                    role++) {\n-            if (first) {\n-                os << \" with the following roles: \" << role->name;\n-                first = false;\n-            }\n-            else {\n-               os << \", \" << role->name;\n+        if (_roles) {\n+            for (std::vector<User::RoleData>::const_iterator role = _roles->begin();\n+                        role != _roles->end();\n+                        role++) {\n+                if (first) {\n+                    os << \" with the following roles: \" << role->name;\n+                    first = false;\n+                }\n+                else {\n+                   os << \", \" << role->name;\n+                }\n             }\n         }\n         os << '.';\n","summary":[{"filename":"src/audit/audit_indexes_collections_databases.cpp","additions":1,"deletions":1},{"filename":"src/audit/audit_user_management.cpp","additions":11,"deletions":9}]}}],"patches":[{"name":"","githash":"04c63390531b22857bd8110761b5cf631278f9b6","patch_set":{"patch":"diff --git a/jstests/slowNightly/ttl1.js b/jstests/slowNightly/ttl1.js\nindex f795d8b..50dae56 100644\n--- a/jstests/slowNightly/ttl1.js\n+++ b/jstests/slowNightly/ttl1.js\n@@ -1,21 +1,33 @@\n /**\n  * Part 1: Simple test of TTL.  Create a new collection with 24 docs, with timestamps at one hour\n  *         intervals, from now-minus-23 hours ago until now.  Also add some docs with non-date\n- *         values.  Then create a TTL index that expires all docs older than ~5.5 hours (20000\n- *         seconds).  Wait 70 seconds (TTL monitor runs every 60) and check that 18 docs deleted.\n- * Part 2: Add a second TTL index on an identical field. The second index expires docs older than\n+ *         values.  Then create a TTL index that expires all docs older than a string. Wait 70\n+ *         seconds (TTL monitor runs every 60) and check that no documents were deleted.\n+ * Part 2: Add a second TTL index that expires all docs older than ~5.5 hours (20000\n+ *         seconds).  Wait 70 seconds and check that 18 docs deleted.\n+ * Part 3: Add a third TTL index on an identical field. The second index expires docs older than\n  *         ~2.8 hours (10000 seconds). Wait 70 seconds and check that 3 more docs deleted.\n  */\n \n+assertEntryMatches = function(array, regex) {\n+    var found = false;\n+    for (i=0; i<array.length; i++) {\n+        if (regex.test(array[i])) {\n+             found = true;\n+        }\n+    }\n+    assert(found,\n+           \"The regex: \" + regex + \" did not match any entries in the array: \" + array.join('\\n'));\n+}\n // Part 1\n var t = db.ttl1;\n t.drop();\n \n var now = (new Date()).getTime();\n \n-for ( i=0; i<24; i++ ){\n-    var past = new Date( now - ( 3600 * 1000 * i ) );\n-    t.insert( { x : past , y : past } );\n+for (i=0; i<24; i++) {\n+    var past = new Date(now - (3600 * 1000 * i));\n+    t.insert({x: past, y: past, z: past});\n }\n t.insert( { a : 1 } )     //no x value\n t.insert( { x: null } )   //non-date value\n@@ -27,6 +39,18 @@ db.getLastError();\n \n assert.eq( 30 , t.count() );\n \n+t.ensureIndex( { z : 1 } , { expireAfterSeconds : \"20000\" } );\n+\n+sleep(70 * 1000);\n+\n+assert.eq(t.count(), 30);\n+\n+var loggedWarning = false;\n+var log = db.adminCommand({getLog: \"global\"}).log;\n+var msg = RegExp(\"ttl indexes require the expireAfterSeconds\" +\n+                 \" field to be numeric but received a type of:\");\n+assertEntryMatches(log, msg);\n+// Part 2\n t.ensureIndex( { x : 1 } , { expireAfterSeconds : 20000 } );\n \n assert.soon( \n@@ -41,7 +65,7 @@ assert.eq( 12 , t.count() );\n assert.lte( 18, db.serverStatus().metrics.ttl.deletedDocuments );\n assert.lte( 1, db.serverStatus().metrics.ttl.passes );\n \n-// Part 2\n+// Part 3\n t.ensureIndex( { y : 1 } , { expireAfterSeconds : 10000 } );\n \n assert.soon(\ndiff --git a/src/mongo/db/index_rebuilder.cpp b/src/mongo/db/index_rebuilder.cpp\nindex 6f3edbe..430ec1c 100644\n--- a/src/mongo/db/index_rebuilder.cpp\n+++ b/src/mongo/db/index_rebuilder.cpp\n@@ -54,27 +54,21 @@ namespace mongo {\n         std::vector<std::string> dbNames;\n         getDatabaseNames(dbNames);\n \n-        std::vector<std::string> nsToCheck;\n         try {\n-            for (std::vector<std::string>::const_iterator it = dbNames.begin();\n-                 it < dbNames.end();\n-                 it++) {\n-                const std::string systemNS = *it + \".system.namespaces\";\n-                DBDirectClient cli;\n-                scoped_ptr<DBClientCursor> cursor(cli.query(systemNS, Query()));\n-\n-                // This depends on system.namespaces not changing while we iterate\n-                while (cursor->more()) {\n-                    BSONObj nsDoc = cursor->nextSafe();\n-                    nsToCheck.push_back(nsDoc[\"name\"].valuestrsafe());\n-                }\n+            std::list<std::string> collNames;\n+            for (std::vector<std::string>::const_iterator dbName = dbNames.begin();\n+                 dbName < dbNames.end();\n+                 dbName++) {\n+                NamespaceIndex nsi(storageGlobalParams.dbpath, *dbName);\n+\n+                nsi.getNamespaces(collNames, /* onlyCollections */ true);\n             }\n             {\n                 boost::unique_lock<boost::mutex> lk(ReplSet::rss.mtx);\n                 ReplSet::rss.indexRebuildDone = true;\n                 ReplSet::rss.cond.notify_all();\n             }\n-            checkNS(nsToCheck);\n+            checkNS(collNames);\n         }\n         catch (const DBException&) {\n             warning() << \"index rebuilding did not complete\" << endl;\n@@ -87,9 +81,9 @@ namespace mongo {\n         LOG(1) << \"checking complete\" << endl;\n     }\n \n-    void IndexRebuilder::checkNS(const std::vector<std::string>& nsToCheck) {\n+    void IndexRebuilder::checkNS(const std::list<std::string>& nsToCheck) {\n         bool firstTime = true;\n-        for (std::vector<std::string>::const_iterator it = nsToCheck.begin();\n+        for (std::list<std::string>::const_iterator it = nsToCheck.begin();\n                 it != nsToCheck.end();\n                 ++it) {\n             // This write lock is held throughout the index building process\ndiff --git a/src/mongo/db/index_rebuilder.h b/src/mongo/db/index_rebuilder.h\nindex 08f10f7..110736f 100644\n--- a/src/mongo/db/index_rebuilder.h\n+++ b/src/mongo/db/index_rebuilder.h\n@@ -44,10 +44,10 @@ namespace mongo {\n \n     private:\n         /**\n-         * Check each collection in the passed in vector to see if it has any in-progress index\n+         * Check each collection in the passed in list to see if it has any in-progress index\n          * builds that need to be retried.  If so, calls retryIndexBuild.\n          */\n-        void checkNS(const std::vector<std::string>& nsToCheck);\n+        void checkNS(const std::list<std::string>& nsToCheck);\n \n         /**\n          * Actually retry an index build on a given namespace.\ndiff --git a/src/mongo/db/repl/rs.cpp b/src/mongo/db/repl/rs.cpp\nindex b67cf17..a096f78 100644\n--- a/src/mongo/db/repl/rs.cpp\n+++ b/src/mongo/db/repl/rs.cpp\n@@ -644,21 +644,11 @@ namespace {\n         // this is a shortcut for simple changes\n         if( additive ) {\n             log() << \"replSet info : additive change to configuration\" << rsLog;\n-            for( list<ReplSetConfig::MemberCfg*>::const_iterator i = newOnes.begin(); i != newOnes.end(); i++ ) {\n-                ReplSetConfig::MemberCfg *m = *i;\n-                Member *mi = new Member(m->h, m->_id, m, false);\n-\n-                /** we will indicate that new members are up() initially so that we don't relinquish our\n-                    primary state because we can't (transiently) see a majority.  they should be up as we\n-                    check that new members are up before getting here on reconfig anyway.\n-                    */\n-                mi->get_hbinfo().health = 0.1;\n-\n-                _members.push(mi);\n-                startHealthTaskFor(mi);\n-            }\n-\n             if (updateConfigs) {\n+                // we have new configs for existing members, so we need to repopulate _members\n+                // with the most recent configs\n+                _members.orphanAll();\n+\n                 // for logging\n                 string members = \"\";\n \n@@ -684,6 +674,22 @@ namespace {\n                 }\n             }\n \n+            // add any new members\n+            for (list<ReplSetConfig::MemberCfg*>::const_iterator i = newOnes.begin();\n+                    i != newOnes.end();\n+                    i++) {\n+                ReplSetConfig::MemberCfg *m = *i;\n+                Member *mi = new Member(m->h, m->_id, m, false);\n+\n+                // we will indicate that new members are up() initially so that we don't relinquish\n+                // our primary state because we can't (transiently) see a majority. they should be\n+                // up as we check that new members are up before getting here on reconfig anyway.\n+                mi->get_hbinfo().health = 0.1;\n+\n+                _members.push(mi);\n+                startHealthTaskFor(mi);\n+            }\n+\n             // if we aren't creating new members, we may have to update the\n             // groups for the current ones\n             _cfg->updateMembers(_members);\ndiff --git a/src/mongo/db/repl/rs_sync.cpp b/src/mongo/db/repl/rs_sync.cpp\nindex bfa5442..f244003 100644\n--- a/src/mongo/db/repl/rs_sync.cpp\n+++ b/src/mongo/db/repl/rs_sync.cpp\n@@ -258,7 +258,7 @@ namespace replset {\n         \n         std::vector< std::vector<BSONObj> > writerVectors(theReplSet->replWriterThreadCount);\n         fillWriterVectors(ops, &writerVectors);\n-        LOG(1) << \"replication batch size is \" << ops.size() << endl;\n+        LOG(2) << \"replication batch size is \" << ops.size() << endl;\n         // We must grab this because we're going to grab write locks later.\n         // We hold this mutex the entire time we're writing; it doesn't matter\n         // because all readers are blocked anyway.\ndiff --git a/src/mongo/db/server_options.cpp b/src/mongo/db/server_options.cpp\nindex bbd60e8..46deb38 100644\n--- a/src/mongo/db/server_options.cpp\n+++ b/src/mongo/db/server_options.cpp\n@@ -34,6 +34,7 @@\n #define SYSLOG_NAMES\n #include <syslog.h>\n #endif\n+#include <boost/filesystem.hpp>\n \n #include \"mongo/base/status.h\"\n #include \"mongo/bson/util/builder.h\"\n@@ -586,7 +587,8 @@ namespace {\n         }\n \n         if (params.count(\"keyFile\")) {\n-            serverGlobalParams.keyFile = params[\"keyFile\"].as<string>();\n+            serverGlobalParams.keyFile = boost::filesystem::absolute(\n+                                            params[\"keyFile\"].as<string>()).generic_string();\n         }\n \n         if ( params.count(\"pidfilepath\")) {\ndiff --git a/src/mongo/db/structure/collection_info_cache.cpp b/src/mongo/db/structure/collection_info_cache.cpp\nindex 8643446..7115384 100644\n--- a/src/mongo/db/structure/collection_info_cache.cpp\n+++ b/src/mongo/db/structure/collection_info_cache.cpp\n@@ -42,8 +42,10 @@\n namespace mongo {\n \n     CollectionInfoCache::CollectionInfoCache( Collection* collection )\n-        : _collection( collection ), _qcCacheMutex( \"_qcCacheMutex\" ) {\n-    }\n+        : _collection( collection ),\n+          _keysComputed( false ),\n+          _qcCacheMutex( \"_qcCacheMutex\" ),\n+          _qcWriteCount( 0 ) {}\n \n     void CollectionInfoCache::reset() {\n         Lock::assertWriteLocked( _collection->ns().ns() );\ndiff --git a/src/mongo/db/ttl.cpp b/src/mongo/db/ttl.cpp\nindex 88d83fe..15d5dbe 100644\n--- a/src/mongo/db/ttl.cpp\n+++ b/src/mongo/db/ttl.cpp\n@@ -92,6 +92,12 @@ namespace mongo {\n                     error() << \"key for ttl index can only have 1 field\" << endl;\n                     continue;\n                 }\n+                if (!idx[secondsExpireField].isNumber()) {\n+                    log() << \"ttl indexes require the \" << secondsExpireField << \" field to be \"\n+                          << \"numeric but received a type of: \"\n+                          << typeName(idx[secondsExpireField].type());\n+                    continue;\n+                }\n \n                 BSONObj query;\n                 {\n","summary":[{"filename":"jstests/slowNightly/ttl1.js","additions":31,"deletions":7},{"filename":"src/mongo/db/index_rebuilder.cpp","additions":10,"deletions":16},{"filename":"src/mongo/db/index_rebuilder.h","additions":2,"deletions":2},{"filename":"src/mongo/db/repl/rs.cpp","additions":20,"deletions":14},{"filename":"src/mongo/db/repl/rs_sync.cpp","additions":1,"deletions":1},{"filename":"src/mongo/db/server_options.cpp","additions":3,"deletions":1},{"filename":"src/mongo/db/structure/collection_info_cache.cpp","additions":4,"deletions":2},{"filename":"src/mongo/db/ttl.cpp","additions":6,"deletions":0}]}}],"tasks":["slow_nightly_tests","core","core_auth","failpoints","failpoints_auth","disk","disk_auth","tool","tool_auth","auth","client","client_auth","js","js_auth","js_small_oplog","replicasets","replicasets_auth","durability","durability_auth","mongosTest","mongosTest_auth","sharding","sharding_auth","replication","replication_auth","clone","clone_auth","parallel","aggregation","aggregation_auth","slow_weekly_tests","ssl","mongo-perf"],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"52654a6e3ff1222a2f000002"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["all"],"create_time":{"$date":"2013-10-21T15:38:22.746Z"},"desc":"all","githash":"428be313f4ac309d792de049fbab966c19f02bb9","patches":[{"name":"","githash":"428be313f4ac309d792de049fbab966c19f02bb9","patch_set":{"patch":"diff --git a/jstests/tool/csvexport_dates.js b/jstests/tool/csvexport_dates.js\ndeleted file mode 100644\nindex 6787d1c..0000000\n--- a/jstests/tool/csvexport_dates.js\n+++ /dev/null\n@@ -1,77 +0,0 @@\n-// Test that we can handle various edge cases of a date type in a csv export\n-\n-t = new ToolTest(\"csvexport_date_before_epoch\")\n-\n-c = t.startDB(\"foo\");\n-\n-function test(date) {\n-\n-    if (date.valueOf() < 0 && _isWindows()) {\n-        // some versions of windows (but not all) fail with dates before 1970\n-        print(\"skipping test of \" + date.tojson() +\n-              \" because system might not support dates before 1970\");\n-        return;\n-    }\n-\n-    print(\"testing \" + date);\n-\n-    c.drop();\n-\n-    assert.eq(0, c.count(), \"initial collection not empty\");\n-\n-    c.insert({ _id : 1, date : date });\n-\n-    assert.eq(1, c.count(), \"failed to insert document into collection\");\n-\n-    t.runTool(\"export\", \"--out\", t.extFile, \"-d\", t.baseName, \"-c\", \"foo\", \"--csv\", \"-f\",\n-              \"_id,date\")\n-\n-    c.drop()\n-\n-    assert.eq(0, c.count(), \"failed to drop collection\")\n-\n-    t.runTool(\"import\", \"--file\", t.extFile, \"-d\", t.baseName, \"-c\", \"foo\", \"--type\", \"csv\",\n-              \"--headerline\");\n-\n-    assert.soon(1 + \" == c.count()\", \"after import\");\n-\n-    // Note: Exporting and Importing to/from CSV is not designed to be round-trippable\n-    var expected = { \"date\" : date.toISOString() };\n-\n-    var actual = c.findOne();\n-\n-    delete actual._id\n-    assert.eq(expected, actual, \"imported doc did not match expected\");\n-}\n-\n-// Basic test\n-test(ISODate('1960-01-02 03:04:05.006Z'));\n-\n-// Testing special rounding rules for seconds\n-test(ISODate('1960-01-02 03:04:04.999Z')); // second = 4\n-test(ISODate('1960-01-02 03:04:05.000Z')); // second = 5\n-test(ISODate('1960-01-02 03:04:05.001Z')); // second = 5\n-test(ISODate('1960-01-02 03:04:05.999Z')); // second = 5\n-\n-// Test date before 1900 (negative tm_year values from gmtime)\n-// Skip this test on systems where a time_t is not big enough to store the value\n-buildInfo = t.db.adminCommand(\"buildInfo\");\n-if (buildInfo.bits >= 64) {\n-    test(ISODate('1860-01-02 03:04:05.006Z'));\n-}\n-\n-// Test with time_t == -1 and 0\n-test(new Date(-1000));\n-test(new Date(0));\n-\n-// Testing dates between 1970 and 2000\n-test(ISODate('1970-01-01 00:00:00.000Z'));\n-test(ISODate('1970-01-01 00:00:00.999Z'));\n-test(ISODate('1980-05-20 12:53:64.834Z'));\n-test(ISODate('1999-12-31 00:00:00.000Z'));\n-test(ISODate('1999-12-31 23:59:59.999Z'));\n-\n-// Test date > 2000 for completeness (using now)\n-test(new Date());\n-\n-t.stop();\ndiff --git a/src/mongo/db/pipeline/expression.cpp b/src/mongo/db/pipeline/expression.cpp\nindex cf9eaca..8fb62a3 100644\n--- a/src/mongo/db/pipeline/expression.cpp\n+++ b/src/mongo/db/pipeline/expression.cpp\n@@ -1437,7 +1437,9 @@ namespace {\n \n     Value ExpressionMillisecond::evaluateInternal(const Variables& vars) const {\n         Value date(vpOperand[0]->evaluateInternal(vars));\n-        return Value(extractMillisPortion(date.coerceToDate()));\n+        const int ms = date.coerceToDate() % 1000LL;\n+        // adding 1000 since dates before 1970 would have negative ms\n+        return Value(ms >= 0 ? ms : 1000 + ms);\n     }\n \n     REGISTER_EXPRESSION(\"$millisecond\", ExpressionMillisecond::parse);\ndiff --git a/src/mongo/db/pipeline/value.cpp b/src/mongo/db/pipeline/value.cpp\nindex 26f01e8..9139f0c 100644\n--- a/src/mongo/db/pipeline/value.cpp\n+++ b/src/mongo/db/pipeline/value.cpp\n@@ -426,7 +426,22 @@ namespace mongo {\n     }\n \n     time_t Value::coerceToTimeT() const {\n-        return millisToTimeT(coerceToDate());\n+        long long millis = coerceToDate();\n+        if (millis < 0) {\n+            // We want the division below to truncate toward -inf rather than 0\n+            // eg Dec 31, 1969 23:59:58.001 should be -2 seconds rather than -1\n+            // This is needed to get the correct values from coerceToTM\n+            if ( -1999 / 1000 != -2) { // this is implementation defined\n+                millis -= 1000-1;\n+            }\n+        }\n+        const long long seconds = millis / 1000;\n+\n+        uassert(16421, \"Can't handle date values outside of time_t range\",\n+               seconds >= std::numeric_limits<time_t>::min() &&\n+               seconds <= std::numeric_limits<time_t>::max());\n+\n+        return static_cast<time_t>(seconds);\n     }\n     tm Value::coerceToTm() const {\n         // See implementation in Date_t.\ndiff --git a/src/mongo/util/time_support.cpp b/src/mongo/util/time_support.cpp\nindex fc7b71e..7619050 100644\n--- a/src/mongo/util/time_support.cpp\n+++ b/src/mongo/util/time_support.cpp\n@@ -112,13 +112,12 @@ namespace mongo {\n         const int bufSize = 32;\n         char buf[bufSize];\n         struct tm t;\n-        time_t_to_Struct(millisToTimeT(static_cast<long long>(date.millis)), &t, local);\n+        time_t_to_Struct(date.toTimeT(), &t, local);\n         int pos = strftime(buf, bufSize, MONGO_ISO_DATE_FMT_NO_TZ, &t);\n         fassert(16981, 0 < pos);\n         char* cur = buf + pos;\n         int bufRemaining = bufSize - pos;\n-        pos = snprintf(cur, bufRemaining, \".%03d\",\n-                       extractMillisPortion(static_cast<long long>(date.millis)));\n+        pos = snprintf(cur, bufRemaining, \".%03d\", static_cast<int32_t>(date.asInt64() % 1000));\n         fassert(16982, bufRemaining > pos && pos > 0);\n         cur += pos;\n         bufRemaining -= pos;\n@@ -183,30 +182,6 @@ namespace mongo {\n         return millis / 1000;\n     }\n \n-    time_t millisToTimeT(long long millis) {\n-        if (millis < 0) {\n-            // We want the division below to truncate toward -inf rather than 0\n-            // eg Dec 31, 1969 23:59:58.001 should be -2 seconds rather than -1\n-            // This is needed to get the correct values from coerceToTM\n-            if ( -1999 / 1000 != -2) { // this is implementation defined\n-                millis -= 1000-1;\n-            }\n-        }\n-        const long long seconds = millis / 1000;\n-\n-        uassert(16421, \"Can't handle date values outside of time_t range\",\n-               seconds >= std::numeric_limits<time_t>::min() &&\n-               seconds <= std::numeric_limits<time_t>::max());\n-\n-        return static_cast<time_t>(seconds);\n-    }\n-\n-    int extractMillisPortion(long long millisSinceEpoch) {\n-        const int ms = millisSinceEpoch % 1000LL;\n-        // adding 1000 since dates before 1970 would have negative ms\n-        return ms >= 0 ? ms : 1000 + ms;\n-    }\n-\n     std::string dateToCtimeString(Date_t date) {\n         time_t t = date.toTimeT();\n         char buf[64];\ndiff --git a/src/mongo/util/time_support.h b/src/mongo/util/time_support.h\nindex 1043a65..46cee85 100644\n--- a/src/mongo/util/time_support.h\n+++ b/src/mongo/util/time_support.h\n@@ -78,18 +78,6 @@ namespace mongo {\n      */\n     std::string dateToCtimeString(Date_t date);\n \n-    /**\n-     * Converts millis to time_t, doing correct division for negative millis, and uasserting that\n-     * the result falls within the valid range of a time_t.\n-     */\n-    time_t millisToTimeT(long long millis);\n-\n-    /**\n-     * Returns the millis since the last whole second of the given millis since epoch, and correctly\n-     * handles dates before epoch.\n-     */\n-    int extractMillisPortion(long long millisSinceEpoch);\n-\n     boost::gregorian::date currentDate();\n \n     // parses time of day in \"hh:mm\" format assuming 'hh' is 00-23\ndiff --git a/src/mongo/util/time_support_test.cpp b/src/mongo/util/time_support_test.cpp\nindex 12a72d4..c459c12 100644\n--- a/src/mongo/util/time_support_test.cpp\n+++ b/src/mongo/util/time_support_test.cpp\n@@ -63,53 +63,6 @@ namespace {\n                           dateToISOStringUTC(Date_t(2781455351100ULL)));\n         ASSERT_EQUALS(std::string(\"2013-02-20T18:29:11.100Z\"),\n                       dateToISOStringUTC(Date_t(1361384951100ULL)));\n-\n-        // Basic test\n-#ifndef _WIN32 // Negative Dates don't currently work on Windows\n-        ASSERT_EQUALS(std::string(\"1960-01-02T03:04:05.006Z\"),\n-                      dateToISOStringUTC(Date_t(-315521754994LL)));\n-#endif\n-\n-        // Testing special rounding rules for seconds\n-#ifndef _WIN32 // Negative Dates don't currently work on Windows\n-        ASSERT_EQUALS(std::string(\"1960-01-02T03:04:04.999Z\"),\n-                      dateToISOStringUTC(Date_t(-315521755001LL))); // second = 4\n-        ASSERT_EQUALS(std::string(\"1960-01-02T03:04:05.000Z\"),\n-                      dateToISOStringUTC(Date_t(-315521755000LL))); // second = 5\n-        ASSERT_EQUALS(std::string(\"1960-01-02T03:04:05.001Z\"),\n-                      dateToISOStringUTC(Date_t(-315521754999LL))); // second = 5\n-        ASSERT_EQUALS(std::string(\"1960-01-02T03:04:05.999Z\"),\n-                      dateToISOStringUTC(Date_t(-315521754001LL))); // second = 5\n-#endif\n-\n-        // Test date before 1900 (negative tm_year values from gmtime)\n-#ifndef _WIN32 // Negative Dates don't currently work on Windows\n-        if (!isTimeTSmall)\n-            ASSERT_EQUALS(std::string(\"1860-01-02T03:04:05.006Z\"),\n-                          dateToISOStringUTC(Date_t(-3471195354994LL)));\n-#endif\n-\n-        // Test with time_t == -1\n-#ifndef _WIN32 // Negative Dates don't currently work on Windows\n-        ASSERT_EQUALS(std::string(\"1969-12-31T23:59:59.000Z\"),\n-                      dateToISOStringUTC(Date_t(-1000LL)));\n-#endif\n-\n-        // Testing dates between 1970 and 2000\n-        ASSERT_EQUALS(std::string(\"1970-01-01T00:00:00.000Z\"),\n-                      dateToISOStringUTC(Date_t(0ULL)));\n-        ASSERT_EQUALS(std::string(\"1970-01-01T00:00:00.999Z\"),\n-                      dateToISOStringUTC(Date_t(999ULL)));\n-        ASSERT_EQUALS(std::string(\"1980-05-20T12:54:04.834Z\"),\n-                      dateToISOStringUTC(Date_t(327675244834ULL)));\n-        ASSERT_EQUALS(std::string(\"1999-12-31T00:00:00.000Z\"),\n-                      dateToISOStringUTC(Date_t(946598400000ULL)));\n-        ASSERT_EQUALS(std::string(\"1999-12-31T23:59:59.999Z\"),\n-                      dateToISOStringUTC(Date_t(946684799999ULL)));\n-\n-        // Test date > 2000 for completeness (using now)\n-        ASSERT_EQUALS(std::string(\"2013-10-11T23:20:12.072Z\"),\n-                      dateToISOStringUTC(Date_t(1381533612072ULL)));\n     }\n \n     TEST(TimeFormatting, DateAsISO8601Local) {\n","summary":[{"filename":"jstests/tool/csvexport_dates.js","additions":0,"deletions":77},{"filename":"src/mongo/db/pipeline/expression.cpp","additions":3,"deletions":1},{"filename":"src/mongo/db/pipeline/value.cpp","additions":16,"deletions":1},{"filename":"src/mongo/util/time_support.cpp","additions":2,"deletions":27},{"filename":"src/mongo/util/time_support.h","additions":0,"deletions":12},{"filename":"src/mongo/util/time_support_test.cpp","additions":0,"deletions":47}]}}],"tasks":[],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"52691f903ff1223136000001"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["cxx11-ubuntu1204-64","linux-64","osx-108-cxx11-debug","osx-108-debug","rhel-57-64-bit","solaris-64-bit","windows-32","windows-64-2k8"],"create_time":{"$date":"2013-10-24T13:24:32.386Z"},"desc":"SERVER-11333 test run 4","githash":"d431dc6ca4b15bed750463fccd334d3b681da73e","patches":[{"name":"","githash":"d431dc6ca4b15bed750463fccd334d3b681da73e","patch_set":{"patch":"diff --git a/SConstruct b/SConstruct\nindex 5f33a58..4d768dc 100644\n--- a/SConstruct\n+++ b/SConstruct\n@@ -201,6 +201,7 @@ add_option( \"static\" , \"fully static build\" , 0 , False )\n add_option( \"static-libstdc++\" , \"statically link libstdc++\" , 0 , False )\n add_option( \"lto\", \"enable link time optimizations (experimental, except with MSVC)\" , 0 , True )\n add_option( \"dynamic-windows\", \"dynamically link on Windows\", 0, True)\n+add_option( \"disable-declspec-thread\", \"don't use __declspec(thread) on Windows\", 0, True)\n \n # base compile flags\n add_option( \"64\" , \"whether to force 64 bit\" , 0 , True , \"force64\" )\n@@ -1321,6 +1322,51 @@ def doConfigure(myenv):\n     if linux:\n         AddToCCFLAGSIfSupported(myenv, \"-fno-builtin-memcmp\")\n \n+    # When using msvc, check for support for __declspec(thread), unless we have been asked\n+    # explicitly not to use it. For other compilers, see if __thread works.\n+    if using_msvc():\n+        haveDeclSpecThread = False\n+        if not has_option(\"disable-declspec-thread\"):\n+            def CheckDeclspecThread(context):\n+                test_body = \"\"\"\n+                __declspec( thread ) int tsp_int;\n+                int main(int argc, char* argv[]) {\n+                    tsp_int = argc;\n+                    return 0;\n+                }\n+                \"\"\"\n+                context.Message('Checking for __declspec(thread)... ')\n+                ret = context.TryLink(textwrap.dedent(test_body), \".cpp\")\n+                context.Result(ret)\n+                return ret\n+            conf = Configure(myenv, help=False, custom_tests = {\n+                'CheckDeclspecThread' : CheckDeclspecThread,\n+            })\n+            haveDeclSpecThread = conf.CheckDeclspecThread()\n+            conf.Finish()\n+        if haveDeclSpecThread:\n+            myenv.Append(CPPDEFINES=['MONGO_HAVE___DECLSPEC_THREAD'])\n+    else:\n+        def CheckUUThread(context):\n+            test_body = \"\"\"\n+            __thread int tsp_int;\n+            int main(int argc, char* argv[]) {\n+                tsp_int = argc;\n+                return 0;\n+            }\n+            \"\"\"\n+            context.Message('Checking for __thread... ')\n+            ret = context.TryLink(textwrap.dedent(test_body), \".cpp\")\n+            context.Result(ret)\n+            return ret\n+        conf = Configure(myenv, help=False, custom_tests = {\n+            'CheckUUThread' : CheckUUThread,\n+        })\n+        haveUUThread = conf.CheckUUThread()\n+        conf.Finish()\n+        if haveUUThread:\n+            myenv.Append(CPPDEFINES=['MONGO_HAVE___THREAD'])\n+\n     conf = Configure(myenv)\n     libdeps.setup_conftests(conf)\n \ndiff --git a/src/mongo/db/storage/record.cpp b/src/mongo/db/storage/record.cpp\nindex 9f2b354..46e3988 100644\n--- a/src/mongo/db/storage/record.cpp\n+++ b/src/mongo/db/storage/record.cpp\n@@ -395,12 +395,12 @@ namespace mongo {\n \n     \n     // These need to be outside the ps namespace due to the way they are defined\n-#if defined(__linux__) && defined(__GNUC__)\n+#if defined(MONGO_HAVE___THREAD)\n     __thread ps::PointerTable::Data _pointerTableData;\n     ps::PointerTable::Data* ps::PointerTable::getData() { \n         return &_pointerTableData; \n     }\n-#elif defined(_WIN32)\n+#elif defined(MONGO_HAVE___DECLSPEC_THREAD)\n     __declspec( thread ) ps::PointerTable::Data _pointerTableData;\n     ps::PointerTable::Data* ps::PointerTable::getData() { \n         return &_pointerTableData; \ndiff --git a/src/mongo/util/concurrency/threadlocal.h b/src/mongo/util/concurrency/threadlocal.h\nindex 05109ad..a9b0b42 100644\n--- a/src/mongo/util/concurrency/threadlocal.h\n+++ b/src/mongo/util/concurrency/threadlocal.h\n@@ -86,7 +86,7 @@ namespace mongo {\n        a combination here, with the assumption that reset's are infrequent, so that \n        get's are fast.\n     */\n-#if defined(_WIN32) || (defined(__GNUC__) && defined(__linux__))\n+#if defined(MONGO_HAVE___THREAD) || defined(MONGO_HAVE___DECLSPEC_THREAD)\n         \n     template< class T >\n     struct TSP {\n@@ -102,7 +102,7 @@ namespace mongo {\n         }\n     };\n \n-# if defined(_WIN32)\n+# if defined(MONGO_HAVE___DECLSPEC_THREAD)\n \n #  define TSP_DECLARE(T,p) extern TSP<T> p;\n \n@@ -129,7 +129,7 @@ namespace mongo {\n     TSP<T> p;\n # endif\n \n-#elif defined(__APPLE__)\n+#elif defined(_POSIX_THREADS) && (_POSIX_THREADS >= 0)\n     template< class T>\n     struct TSP {\n         pthread_key_t _key;\n","summary":[{"filename":"SConstruct","additions":46,"deletions":0},{"filename":"src/mongo/db/storage/record.cpp","additions":2,"deletions":2},{"filename":"src/mongo/util/concurrency/threadlocal.h","additions":3,"deletions":3}]}}],"tasks":["core","client","js","durability","sharding","aggregation"],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"526983de3ff1224641000001"},"activated":true,"author":"admin","branch":"mongodb-mongo-master","build_variants":["cxx11-ubuntu1204-64","enterprise-linux-64-amazon-ami","enterprise-rhel-57-64-bit","enterprise-rhel-62-64-bit","enterprise-suse11-64","enterprise-ubuntu1204-64","enterprise-windows-64","linux-32","linux-32-debug","linux-64","linux-64-debug","linux-64-debug-duroff","linux-64-duroff","osx-108","osx-108-cxx11-debug","osx-108-debug","osx-108-dur-off","rhel-57-64-bit","solaris-64-bit","windows-32","windows-64","windows-64-2k8","windows-64-2k8-debug","windows-64-debug"],"create_time":{"$date":"2013-10-24T20:32:30.842Z"},"desc":"the right version of ssl_fips","githash":"bc05262b903baafd4a286008ab3323172d8c3275","patches":[{"name":"","githash":"bc05262b903baafd4a286008ab3323172d8c3275","patch_set":{"patch":"diff --git a/jstests/ssl/ssl_fips.js b/jstests/ssl/ssl_fips.js\nindex 76118a7..7b2da1a 100644\n--- a/jstests/ssl/ssl_fips.js\n+++ b/jstests/ssl/ssl_fips.js\n@@ -1,5 +1,4 @@\n // Test mongod start with FIPS mode enabled\n-if (0) { // SERVER-11005\n ports = allocatePorts(1);\n port1 = ports[0];\n var baseName = \"jstests_ssl_ssl_fips\";\n@@ -10,11 +9,21 @@ var md = startMongod(\"--port\", port1, \"--dbpath\",\n                      \"--sslPEMKeyFile\", \"jstests/libs/server.pem\",\n                      \"--sslFIPSMode\");\n \n-var mongo = runMongoProgram(\"mongo\", \"--port\", port1, \"--ssl\",\n-                            \"--sslPEMKeyFile\", \"jstests/libs/client.pem\",\n-                            \"--sslFIPSMode\",\n-                            \"--eval\", \";\");\n+// if mongod didn't start properly\n+if (md != 0) {\n+    print(\"mongod failed to start, checking for FIPS support\");\n+    assert(rawMongoProgramOutput().match(\n+            /this version of mongodb was not compiled with FIPS support/));\n+}\n+else {\n+    // try connecting shell\n+    var mongo = runMongoProgram(\"mongo\", \"--port\", port1, \"--ssl\",\n+                                \"--sslPEMKeyFile\", \"jstests/libs/client.pem\",\n+                                \"--sslFIPSMode\",\n+                                \"--eval\", \";\");\n \n-// 0 is the exit code for success\n-assert(mongo==0);\n+    // 0 is the exit code for success\n+    assert(mongo==0);\n+    // kill mongod\n+    stopMongod(port1, 9);\n }\n","summary":[{"filename":"jstests/ssl/ssl_fips.js","additions":16,"deletions":7}]}}],"tasks":["ssl"],"version":"5273b4b83ff1226c75000003_0","status":"started"}
{"_id":{"$oid":"5f74d99ab2373627c047c5e5"},"desc":"main: EVG-7823 add a commit queue message (#4048)","branch":"evergreen","githash":"a1d2c8f70bf5c543de8b9641ac1ec08def1ddb26","patch_number":234,"author":"admin","version":"5f74d99ab2373627c047c5e5","status":"succeeded","create_time":{"$date":"2020-09-30T19:16:42.440Z"},"start_time":{"$date":"2020-09-30T21:30:05.654Z"},"finish_time":{"$date":"2020-09-30T21:32:16.130Z"},"build_variants":["ubuntu1604"],"tasks":["test-command","test-util","test-db"],"variants_tasks":[{"variant":"ubuntu1604","tasks":["test-command","test-util","test-db"],"displaytasks":[{"name":"asdf"}]}],"sync_at_end_opts":{"timeout":{"$numberLong":"3600000000000"}},"patches":[{"name":"","githash":"a1d2c8f70bf5c543de8b9641ac1ec08def1ddb26","patch_set":{"patch_file_id":"5e4ff3ab850e6136624eaf95","commit_messages":["main: EVG-7823 add a commit queue message (#4048)"],"summary":[{"filename":"self-tests.yml","additions":6,"deletions":0,"description":"main: EVG-7823 add a commit queue message (#4048)"}]},"is_mbox":true}],"parameters":[],"activated":true,"patched_config":"command_type: test\nstepback: true\nignore:\n  - \"*.md\" # don't schedule tests if a commit only changes markdown files\n  - \"scripts/*\" # our scripts are untested, so don't schedule tests for them\n  - \".github/*\" # github CODEOWNERS configuration\n\npost:\n  - func: attach-test-results\n  - command: s3.put\n    type: system\n    params:\n      aws_key: ${aws_key}\n      aws_secret: ${aws_secret}\n      local_files_include_filter:\n        [\n          \"gopath/src/github.com/evergreen-ci/evergreen/bin/output.*.coverage.html\",\n        ]\n      remote_file: evergreen/${task_id}/\n      bucket: mciuploads\n      content_type: text/html\n      permissions: public-read\n      display_name: \"(html) coverage:\"\n  - command: s3.put\n    type: system\n    params:\n      aws_key: ${aws_key}\n      aws_secret: ${aws_secret}\n      local_files_include_filter:\n        [\"gopath/src/github.com/evergreen-ci/evergreen/bin/output.*.coverage\"]\n      remote_file: evergreen/${task_id}/\n      bucket: mciuploads\n      content_type: text/plain\n      permissions: public-read\n      display_name: \"(txt) coverage:\"\n\n#######################################\n#         YAML Templates              #\n#######################################\nvariables:\n  - \u0026run-build\n    # runs a build operations. The task name in evergreen should\n    # correspond to a make target for the build operation.\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n      - command: s3.put\n        type: system\n        params:\n          optional: true\n          aws_key: ${aws_key}\n          aws_secret: ${aws_secret}\n          local_file: gopath/src/github.com/evergreen-ci/evergreen/bin/dist.tar.gz\n          remote_file: evergreen/${build_id}-${build_variant}/evergreen-${task_name}-${revision}.tar.gz\n          bucket: mciuploads\n          content_type: application/x-gzip\n          permissions: public-read\n          display_name: dist.tar.gz\n  - \u0026run-go-test-suite\n    # runs a make target and then uploads gotest output to\n    # evergreen. The test name should correspond to a make target for\n    # that suite\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - \u0026run-go-test-suite-with-docker\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: setup-docker-host\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - \u0026run-go-test-suite-with-mongodb\n    # runs a make target above, but only on systems that have a\n    # running mongod started for testing.\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - \u0026run-go-test-suite-with-mongodb-useast\n    # runs a make target above, but only on systems that have a\n    # running mongod started for testing.\n    name: test\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"${task_name}\", tz: \"America/New_York\" }\n  - \u0026run-smoke-test\n    name: smoke\n    commands:\n      - command: timeout.update\n        params:\n          exec_timeout_secs: 900\n          timeout_secs: 900\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-mongodb\n      - func: run-make\n        vars: { target: \"set-var\" }\n      - func: run-make\n        vars: { target: \"set-project-var\" }\n      - func: run-make\n        vars: { target: \"load-smoke-data\" }\n      - command: subprocess.exec\n        params:\n          silent: true\n          working_dir: gopath/src/github.com/evergreen-ci/evergreen\n          command: bash scripts/setup-smoke-config.sh ${github_token}\n      - func: run-make\n        vars:\n          target: set-smoke-vars\n      - func: run-make\n        vars:\n          target: \"${task_name}\"\n  - \u0026run-smoke-test-with-client-url\n    name: smoke\n    commands:\n      - command: timeout.update\n        params:\n          exec_timeout_secs: 900\n          timeout_secs: 900\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: run-make\n        vars: { target: \"cli\" }\n      - command: s3.put\n        type: system\n        params:\n          aws_key: ${aws_key}\n          aws_secret: ${aws_secret}\n          local_file: gopath/src/github.com/evergreen-ci/evergreen/clients/${goos}_${goarch}/evergreen\n          remote_file: evergreen/${task_id}/evergreen-ci/evergreen/clients/${goos}_${goarch}/evergreen\n          bucket: mciuploads\n          content_type: application/octet-stream\n          permissions: public-read\n          display_name: evergreen\n      - func: setup-mongodb\n      - func: run-make\n        vars: { target: \"set-var\" }\n      - func: run-make\n        vars: { target: \"set-project-var\" }\n      - func: run-make\n        vars: { target: \"load-smoke-data\" }\n      - command: subprocess.exec\n        params:\n          silent: true\n          working_dir: gopath/src/github.com/evergreen-ci/evergreen\n          command: bash scripts/setup-smoke-config.sh ${github_token}\n      - func: run-make\n        vars:\n          target: set-smoke-vars\n      - func: run-make\n        vars:\n          target: \"${task_name}\"\n  - \u0026version-constants\n    nodejs_version: \"6.11.1\"\n  - \u0026run-generate-lint\n    name: generate-lint\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n      - command: s3.put\n        type: system\n        params:\n          aws_key: ${aws_key}\n          aws_secret: ${aws_secret}\n          local_file: gopath/src/github.com/evergreen-ci/evergreen/bin/generate-lint.json\n          remote_file: evergreen/${build_id}-${build_variant}/bin/generate-lint.json\n          bucket: mciuploads\n          content_type: application/json\n          permissions: public-read\n          display_name: generate-lint.json\n      - command: generate.tasks\n        params:\n          files:\n            - gopath/src/github.com/evergreen-ci/evergreen/bin/generate-lint.json\n\n#######################################\n#              Functions              #\n#######################################\nfunctions:\n  get-project:\n    command: git.get_project\n    type: setup\n    params:\n      directory: gopath/src/github.com/evergreen-ci/evergreen\n      token: ${github_token}\n      shallow_clone: true\n  run-make:\n    command: subprocess.exec\n    params:\n      working_dir: gopath/src/github.com/evergreen-ci/evergreen\n      binary: make\n      args: [\"${make_args|}\", \"${target}\"]\n      env:\n        AWS_KEY: ${aws_key}\n        AWS_SECRET: ${aws_secret}\n        CLIENT_URL: https://mciuploads.s3.amazonaws.com/evergreen/${task_id}/evergreen-ci/evergreen/clients/${goos}_${goarch}/evergreen\n        DEBUG_ENABLED: ${debug}\n        DISABLE_COVERAGE: ${disable_coverage}\n        DOCKER_HOST: ${docker_host}\n        EVERGREEN_ALL: \"true\"\n        GOARCH: ${goarch}\n        GO_BIN_PATH: ${gobin}\n        LEGACY_GO_BIN_PATH: ${legacyGobin}\n        GOOS: ${goos}\n        GOPATH: ${workdir}/gopath\n        GOROOT: ${goroot}\n        IS_DOCKER: ${is_docker}\n        KARMA_REPORTER: junit\n        NODE_BIN_PATH: ${nodebin}\n        RACE_DETECTOR: ${race_detector}\n        SETTINGS_OVERRIDE: creds.yml\n        SMOKE_TEST_FILE: ${smoke_test_file}\n        TEST_TIMEOUT: ${test_timeout}\n        TZ: ${tz}\n        VENDOR_PKG: \"github.com/${trigger_repo_owner}/${trigger_repo_name}\"\n        VENDOR_REVISION: ${trigger_revision}\n        XC_BUILD: ${xc_build}\n  setup-credentials:\n    command: subprocess.exec\n    type: setup\n    params:\n      silent: true\n      working_dir: gopath/src/github.com/evergreen-ci/evergreen\n      env:\n        GITHUB_TOKEN: ${github_token}\n        JIRA_SERVER: ${jiraserver}\n        CROWD_SERVER: ${crowdserver}\n        CROWD_USER: ${crowduser}\n        CROWD_PW: ${crowdpw}\n        AWS_KEY: ${aws_key}\n        AWS_SECRET: ${aws_secret}\n      command: bash scripts/setup-credentials.sh\n  setup-mongodb:\n    - command: subprocess.exec\n      type: setup\n      params:\n        env:\n          gobin: /opt/golang/go1.9/bin/go\n          MONGODB_URL: ${mongodb_url}\n          DECOMPRESS: ${decompress}\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen/\n        command: make get-mongodb\n    - command: subprocess.exec\n      type: setup\n      params:\n        background: true\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen/\n        command: make start-mongod\n    - command: subprocess.exec\n      type: setup\n      params:\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen\n        command: make check-mongod\n    - command: subprocess.exec\n      type: setup\n      params:\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen/\n        command: make init-rs\n  setup_docker:\n    - command: shell.exec\n      params:\n        shell: bash\n        script: |\n          gopath/src/github.com/evergreen-ci/evergreen/scripts/setup-docker.sh\n  setup-docker-host:\n    - command: host.create\n      type: setup\n      params:\n        distro: archlinux-parent\n        provider: ec2\n        retries: 3\n        scope: build\n        security_group_ids:\n          - sg-097bff6dd0d1d31d0\n    - command: host.list\n      type: setup\n      params:\n        wait: true\n        timeout_seconds: 900\n        num_hosts: 1\n        path: gopath/src/github.com/evergreen-ci/evergreen/spawned_hosts.json\n    - command: subprocess.exec\n      type: setup\n      params:\n        working_dir: gopath/src/github.com/evergreen-ci/evergreen\n        command: make parse-host-file\n        env:\n          HOST_FILE: spawned_hosts.json\n          GO_BIN_PATH: ${gobin}\n          GOROOT: ${goroot}\n    - command: expansions.update\n      params:\n        file: gopath/src/github.com/evergreen-ci/evergreen/bin/expansions.yml\n\n  attach-test-results:\n    - command: gotest.parse_files\n      type: system\n      params:\n        files:\n          - \"gopath/src/github.com/evergreen-ci/evergreen/bin/output.*\"\n    - command: attach.xunit_results\n      type: system\n      params:\n        files:\n          - \"gopath/src/github.com/evergreen-ci/evergreen/bin/jstests/*.xml\"\n  remove-test-results:\n    - command: shell.exec\n      type: system\n      params:\n        shell: bash\n        script: |\n          set -o xtrace\n          rm gopath/src/github.com/evergreen-ci/evergreen/bin/output.*\n          rm gopath/src/github.com/evergreen-ci/evergreen/bin/jstests/*.xml\n\n#######################################\n#                Tasks                #\n#######################################\n\ntasks:\n  - name: coverage\n    tags: [\"report\"]\n    commands:\n      - command: git.get_project\n        type: setup\n        params:\n          directory: gopath/src/github.com/evergreen-ci/evergreen\n          token: ${github_token}\n          shallow_clone: false\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: build\n      - func: run-make\n        vars:\n          target: \"coverage-html\"\n          make_args: \"-k\"\n          tz: \"America/New_York\"\n\n  - \u003c\u003c: *run-build\n    name: dist-staging\n    patch_only: true\n\n  - \u003c\u003c: *run-smoke-test\n    name: smoke-test-task\n    tags: [\"smoke\"]\n  - \u003c\u003c: *run-smoke-test\n    name: smoke-test-endpoints\n    tags: [\"smoke\"]\n  - \u003c\u003c: *run-smoke-test-with-client-url\n    name: smoke-test-agent-monitor\n    tags: [\"smoke\"]\n  - \u003c\u003c: *run-generate-lint\n\n  - \u003c\u003c: *run-go-test-suite\n    name: js-test\n  - \u003c\u003c: *run-build\n    name: dist\n  - \u003c\u003c: *run-go-test-suite\n    tags: [\"nodb\", \"test\", \"agent\"]\n    name: test-thirdparty-docker\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-auth\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-rest-route\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"agent\"]\n    name: test-rest-client\n  - name: test-rest-model\n    tags: [\"db\", \"test\"]\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars:\n          target: build\n      - func: run-make\n        vars: { target: \"${task_name}\" }\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"test\", \"db\", \"agent\"]\n    name: test-command\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"test\", \"db\"]\n    name: test-units\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"agent\"]\n    name: test-agent\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-rest-data\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"cli\"]\n    name: test-operations\n  - \u003c\u003c: *run-go-test-suite\n    tags: [\"nodb\", \"test\", \"cli\"]\n    name: test-operations-metabuild-generator\n  - \u003c\u003c: *run-go-test-suite\n    tags: [\"nodb\", \"test\", \"cli\"]\n    name: test-operations-metabuild-model\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-db\n  - \u003c\u003c: *run-go-test-suite-with-docker\n    tags: [\"db\", \"test\"]\n    name: test-cloud\n  - \u003c\u003c: *run-go-test-suite\n    tags: [\"nodb\", \"test\"]\n    name: test-cloud-userdata\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-scheduler\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-service\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-evergreen\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\", \"agent\"]\n    name: test-thirdparty\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-trigger\n  - \u003c\u003c: *run-go-test-suite\n    tags: [\"nodb\", \"test\", \"agent\"]\n    name: test-util\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-validator\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-alertrecord\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-artifact\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-build\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-event\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-host\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-notification\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-patch\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-stats\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-task\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-testresult\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-user\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-distro\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-commitqueue\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-model-manifest\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-plugin\n  - \u003c\u003c: *run-go-test-suite-with-mongodb\n    tags: [\"db\", \"test\"]\n    name: test-migrations\n  - \u003c\u003c: *run-go-test-suite-with-mongodb-useast\n    tags: [\"db\", \"test\"]\n    name: test-graphql\n  - name: docker-cleanup\n    commands:\n      - func: get-project\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup_docker\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"test-thirdparty-docker\" }\n  - name: test-repotracker\n    tags: [\"db\", \"test\"]\n    commands:\n      - command: git.get_project\n        type: setup\n        params:\n          directory: gopath/src/github.com/evergreen-ci/evergreen\n          token: ${github_token}\n          shallow_clone: false\n      - func: run-make\n        vars:\n          target: get-go-imports\n      - func: setup-credentials\n      - func: setup-mongodb\n      - func: run-make\n        vars:\n          target: revendor\n      - func: run-make\n        vars: { target: \"test-repotracker\" }\n\nbuildvariants:\n  - name: ubuntu1604\n    display_name: Ubuntu 16.04\n    run_on:\n      - ubuntu1604-test\n      - ubuntu1604-build\n    expansions:\n      disable_coverage: yes\n      goos: linux\n      goarch: amd64\n      nodebin: /opt/node/bin\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz\n    display_tasks:\n      - name: \"asdf\"\n        execution_tasks:\n          - test-command\n          - test-util\n          - test-db\n    tasks:\n      - name: \"dist\"\n      - name: \"dist-staging\"\n      - name: \".smoke\"\n      - name: \".test\"\n      - name: \"js-test\"\n\n  - name: ubuntu1604-docker\n    display_name: Ubuntu 16.04 (Docker)\n    run_on:\n      - ubuntu1604-container\n    expansions:\n      goos: linux\n      goarch: amd64\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.3.tgz\n      test_timeout: 15m\n      nodebin: /opt/node/bin\n      is_docker: \"true\"\n    tasks:\n      - name: \"dist\"\n      - name: \".smoke\"\n      - name: \".test\"\n\n  - name: race-detector\n    display_name: Race Detector\n    run_on:\n      - archlinux-test\n      - archlinux-build\n    expansions:\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.3.tgz\n      race_detector: true\n      test_timeout: 15m\n    tasks:\n      - name: \".test\"\n\n  - name: lint\n    display_name: Lint\n    run_on:\n      - archlinux-test\n      - archlinux-build\n    expansions:\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n    tasks:\n      - name: generate-lint\n\n  - name: coverage\n    display_name: Coverage\n    run_on:\n      - archlinux-test\n      - archlinux-build\n    expansions:\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.3.tgz\n      test_timeout: 15m\n    tasks:\n      - name: \".report\"\n        stepback: false\n\n  - name: osx\n    display_name: OSX\n    batchtime: 2880\n    run_on:\n      - macos-1014\n    expansions:\n      disable_coverage: yes\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/osx/mongodb-osx-ssl-x86_64-4.0.3.tgz\n    tasks:\n      - name: \"dist\"\n      - name: \".test\"\n\n  - name: windows\n    display_name: Windows\n    run_on:\n      - windows-64-vs2015-small\n      - windows-64-vs2015-test\n      - windows-64-vs2015-small\n      - windows-64-vs2015-large\n      - windows-64-vs2015-compile\n      - windows-64-vs2013-test\n      - windows-64-vs2013-compile\n      - windows-64-vs2017-test\n      - windows-64-vs2017-compile\n    expansions:\n      disable_coverage: yes\n      gobin: /cygdrive/c/golang/go1.11/bin/go\n      goroot: c:/golang/go1.11\n      legacyGobin: /cygdrive/c/golang/go1.9/bin/go\n      mongodb_url: https://fastdl.mongodb.org/win32/mongodb-win32-x86_64-2008plus-ssl-4.0.3.zip\n      extension: \".exe\"\n      archiveExt: \".zip\"\n    tasks:\n      - name: \".agent .test\"\n      - name: \".cli .test\"\n\n  - name: ubuntu1604-arm64\n    display_name: Ubuntu 16.04 ARM\n    batchtime: 2880\n    run_on:\n      - ubuntu1604-arm64-small\n    expansions:\n      disable_coverage: yes\n      xc_build: yes\n      goarch: arm64\n      goos: linux\n      gobin: /opt/golang/go1.13/bin/go\n      goroot: /opt/golang/go1.13\n      legacyGobin: /opt/golang/go1.9/bin/go\n      mongodb_url: https://downloads.mongodb.com/linux/mongodb-linux-arm64-enterprise-ubuntu1604-4.0.3.tgz\n    tasks:\n      - name: \".agent .test\"\n  - name: linux-docker\n    display_name: ArchLinux (Docker)\n    run_on:\n      - archlinux-test\n    expansions:\n      goos: linux\n      goarch: amd64\n    tasks:\n      - name: \"docker-cleanup\"\n","alias":"","merge_patch":""}
{"_id":{"$oid":"526983de3ff1224641000002"},"activated":true,"author":"you","branch":"logkeeper","create_time":{"$date":"2013-10-24T20:32:30.842Z"},"desc":"patch description here","githash":"bc05262b903baafd4a286008ab3323172d8c3275","patches":[{"name":"","githash":"bc05262b903baafd4a286008ab3323172d8c3275","patch_set":{"patch":"diff --git a/jstests/ssl/ssl_fips.js b/jstests/ssl/ssl_fips.js\nindex 76118a7..7b2da1a 100644\n--- a/jstests/ssl/ssl_fips.js\n+++ b/jstests/ssl/ssl_fips.js\n@@ -1,5 +1,4 @@\n // Test mongod start with FIPS mode enabled\n-if (0) { // SERVER-11005\n ports = allocatePorts(1);\n port1 = ports[0];\n var baseName = \"jstests_ssl_ssl_fips\";\n@@ -10,11 +9,21 @@ var md = startMongod(\"--port\", port1, \"--dbpath\",\n                      \"--sslPEMKeyFile\", \"jstests/libs/server.pem\",\n                      \"--sslFIPSMode\");\n \n-var mongo = runMongoProgram(\"mongo\", \"--port\", port1, \"--ssl\",\n-                            \"--sslPEMKeyFile\", \"jstests/libs/client.pem\",\n-                            \"--sslFIPSMode\",\n-                            \"--eval\", \";\");\n+// if mongod didn't start properly\n+if (md != 0) {\n+    print(\"mongod failed to start, checking for FIPS support\");\n+    assert(rawMongoProgramOutput().match(\n+            /this version of mongodb was not compiled with FIPS support/));\n+}\n+else {\n+    // try connecting shell\n+    var mongo = runMongoProgram(\"mongo\", \"--port\", port1, \"--ssl\",\n+                                \"--sslPEMKeyFile\", \"jstests/libs/client.pem\",\n+                                \"--sslFIPSMode\",\n+                                \"--eval\", \";\");\n \n-// 0 is the exit code for success\n-assert(mongo==0);\n+    // 0 is the exit code for success\n+    assert(mongo==0);\n+    // kill mongod\n+    stopMongod(port1, 9);\n }\n","summary":[{"filename":"jstests/ssl/ssl_fips.js","additions":16,"deletions":7}]}}],"tasks":["ssl"],"status":"created"}
{ "_id" : {"$oid": "5e6bb9e23066155a993e0f1b"}, "desc" : "Patch with display tasks", "branch" : "evergreen", "githash" : "25ab18d7ed2775f27be77d8135ddd841c78cfe28", "patch_number" : 452, "author" : "admin", "version" : "", "status" : "created", "create_time" : {"$date": "2020-03-13T16:50:42.981Z"}, "start_time" : {"$date": "0001-01-01T00:00:00Z"}, "finish_time" : {"$date": "0001-01-01T00:00:00Z"}, "build_variants" : [ "ubuntu1604" ], "tasks" : [ "test-graphql" ], "variants_tasks" : [ { "variant" : "ubuntu1604", "tasks" : [ "test-graphql" ], "displaytasks" : [ ] } ], "patches" : [], "activated" : false, "alias" : "", "patched_config" : "buildvariants:\n  - display_name: Ubuntu 16.04\n    name: ubuntu1604\n    modules:\n      - self\n    run_on:\n      - ubuntu1604-test\n    expansions:\n      module_prefix: hello\n    tasks:\n      - name: unit_tests\n      - name: validate_commit_message\n      - name: patch_only_task\n      - name: batchtime_task\n        batchtime: 4\n    display_tasks:\n      - name: display_task\n        execution_tasks:\n          - validate_commit_message\n      - name: display_task2\n        execution_tasks:\n          - unit_tests\n\nfunctions:\n  create virtualenv:\n    - command: shell.exec\n      params:\n        working_dir: src\n        script: |\n          echo \"noop\"\n\nparameters:\n  - key: my_param\n    value: hello world1!\n    description: something to test parameters1\n\npre:\n  - command: git.get_project\n    params:\n      directory: src\n  - func: create virtualenv\n\npost:\n  - command: attach.xunit_results\n    params:\n      file: src/junit-*.xml\n\ntasks:\n  - name: unit_tests\n    commands:\n      - command: shell.exec\n        params:\n          working_dir: src\n          script: |\n            echo \"my_param: ${my_param}, your_param: ${your_param}\"\n  - name: batchtime_task\n    commands:\n      - command: shell.exec\n        params:\n          working_dir: src\n          script: |\n            echo \"noop2\"\n  - name: validate_commit_message\n    commands:\n      - command: shell.exec\n        params:\n          script: |\n            set -o verbose\n            set -o errexit\n            if [ \"${is_commit_queue}\" = \"true\" ]; then\n              cat > commit_message.txt <<END_OF_COMMIT_MSG\n              ${commit_message}\n            END_OF_COMMIT_MSG\n\n              commit_message_content=$(cat commit_message.txt)\n\n              echo \"$commit_message_content\"\n            fi\n\n  - name: my_first_generator\n    commands:\n      - command: generate.tasks\n        params:\n          files:\n            - src/evergreen.json\n  - name: test_release\n    depends_on:\n      - name: unit_tests\n        variant: \"*\"\n    commands:\n      - command: shell.exec\n        params:\n          working_dir: src\n          script: |\n            exit 1\n  - name: patch_only_task\n    patch_only: true\n    commands:\n      - command: shell.exec\n        params:\n          working_dir: src\n          script: |\n            echo \"i am patch only\"\n  - name: task_to_add_via_generator\n    commands:\n      - command: shell.exec\n        params:\n          working_dir: src\n          script: |\n            git log --oneline -n 10\n\nmodules:\n  - name: self\n    repo: git@github.com:evergreen-ci/commit-queue-sandbox.git\n    prefix: modules/${module_prefix}\n    branch: master\n" }